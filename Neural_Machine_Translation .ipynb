{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6czvz5VKO5M"
      },
      "source": [
        "# Notebook for Programming in Problem 4\n",
        "Welcome to the programming portion of the assignment! Each assignment throughout the semester will have a written portion and a programming portion. We will be using [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true), so if you have never used it before, take a quick look through this introduction: [Working with Google Colab](https://docs.google.com/document/d/1LlnXoOblXwW3YX-0yG_5seTXJsb3kRdMMRYqs8Qqum4/edit?usp=sharing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o8HI5JqTvU5"
      },
      "source": [
        "## Learning Objectives\n",
        "In this problem, we will use [PyTorch](https://pytorch.org/) to implement a sequence-to-sequence (seq2seq) transformer model to build a nerual machine translation (NMT) system, which translates from French to English."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObrHyvWvTyGZ"
      },
      "source": [
        "## Writing Code\n",
        "Look for the keyword \"TODO\" and fill in your code in the empty space.\n",
        "You can edit code in the other parts of the notebook too, which can be useful for debugging, but be careful to avoid breaking the provided code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnYMKJlKNXYe"
      },
      "source": [
        "## Installing Packages\n",
        "\n",
        "Install PyTorch using pip. See [https://pytorch.org/](https://pytorch.org/) if you want to install it on your computer.\n",
        "In addition, we will also be needing [huggingface](https://huggingface.co/)'s `transformers` and `datasets` libraries, and [nltk](https://www.nltk.org/) to compute the BLEU score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dRVuiP_JVdT",
        "outputId": "cc1c8988-6a65-4637-a067-e16e9c1e5dd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.27.0\n",
            "  Downloading transformers-4.27.0-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.27.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.0) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.0) (2024.2.2)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.2\n",
            "    Uninstalling transformers-4.40.2:\n",
            "      Successfully uninstalled transformers-4.40.2\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.27.0\n",
            "Collecting datasets==2.10.0\n",
            "  Downloading datasets-2.10.0-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (14.0.2)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets==2.10.0)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (4.66.4)\n",
            "Collecting xxhash (from datasets==2.10.0)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets==2.10.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (24.0)\n",
            "Collecting responses<0.19 (from datasets==2.10.0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.0) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.0) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.0) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.10.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.10.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.10.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.10.0) (2024.2.2)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.10.0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.10.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.10.0) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.10.0) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.10.0) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, responses, multiprocess, datasets\n",
            "Successfully installed datasets-2.10.0 dill-0.3.6 multiprocess-0.70.14 responses-0.18.0 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "# Pytorch is typically already installed in Google Colab (uncomment to install):\n",
        "# !pip install torch==1.8.0\n",
        "# or for GPU support:\n",
        "# !pip install torch==1.8.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install transformers==4.27.0\n",
        "!pip install datasets==2.10.0\n",
        "# NLTK is typically also already installed in Google Colab (uncomment to install):\n",
        "# !pip install nltk==3.8.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw76yPDhOia1"
      },
      "source": [
        "## Download NMT data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL42TT6Tb0S7"
      },
      "source": [
        "We first download the data for NMT, which contains pairs of parallel sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TmD7lPOXOlm2"
      },
      "outputs": [],
      "source": [
        "!wget --quiet https://princeton-nlp.github.io/cos484/assignments/a4/resources.zip\n",
        "!unzip -qo resources.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5TS8PG0Os0f"
      },
      "source": [
        "## Data preprocessing\n",
        "In this section we will write code to load and tokenize the data for NMT.\n",
        "\n",
        "\n",
        "The parallel data is provided as huggingface datasets, one for each split of `train`, `validation` and `test`. We load it via the `load_from_disk` method and inspect its features. If you'd like to know more about these dataset objects, have a look at [this tutorial](https://huggingface.co/docs/datasets/access)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxi3D2oX1iIK",
        "outputId": "5a656a49-c166-4213-eebf-1aacd8027dd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary of splits: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text_en', 'text_fr'],\n",
            "        num_rows: 8701\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text_en', 'text_fr'],\n",
            "        num_rows: 485\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text_en', 'text_fr'],\n",
            "        num_rows: 486\n",
            "    })\n",
            "})\n",
            "First training example: {'text_en': 'i m tough .', 'text_fr': 'je suis dure .'}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_from_disk\n",
        "raw_text_datasets = load_from_disk(\"resources/parallel_en_fr_corpus\")\n",
        "print(\"Summary of splits:\", raw_text_datasets)\n",
        "print(\"First training example:\", raw_text_datasets[\"train\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1NmS9j01iIK"
      },
      "source": [
        "You are also provided with two pre-trained tokenizers for the source and target languages respectively, which we can load with the hugginface transfomers library. [This tutorial](https://huggingface.co/docs/transformers/preprocessing#natural-language-processing) provides an introduction to using pre-trained tokenizers and the powerful `AutoTokenizer` class. The tokenizers are based on byte-pair encodings which break words into smaller units. This is aimed at reducing the sparsity of words, as subwords can be shared between different rare words. If you are interested in learning more, see the paper [Neural Machine Translation of Rare Words with Subword Units](https://www.aclweb.org/anthology/P16-1162.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iqnyk7Xo1iIK",
        "outputId": "d2c02926-bd7a-4743-cd9b-cd67e5662c9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size of source language: 3200\n",
            "Vocab size of target language: 3200\n",
            "\n",
            "*** Example ***\n",
            "Example sentence: we have an example\n",
            "Tokenizer output: {'input_ids': [1, 64, 324, 103, 266, 1490, 92, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "Tokens: ['<s>', '▁we', '▁have', '▁an', '▁ex', 'amp', 'le', '</s>']\n",
            "Reconstructed sentence <s> we have an example</s>\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "source_tokenizer = AutoTokenizer.from_pretrained(\"resources/tokenizer_fr\")\n",
        "target_tokenizer = AutoTokenizer.from_pretrained(\"resources/tokenizer_en\")\n",
        "\n",
        "print(\"Vocab size of source language:\", source_tokenizer.vocab_size)\n",
        "print(\"Vocab size of target language:\", target_tokenizer.vocab_size)\n",
        "\n",
        "# As a demonstration, we will the following English sentence to tokens.\n",
        "example_sentence = \"we have an example\"\n",
        "tokenizer_output = target_tokenizer(example_sentence)\n",
        "print(\"\\n*** Example ***\")\n",
        "print(\"Example sentence:\", example_sentence)\n",
        "print(\"Tokenizer output:\", tokenizer_output)\n",
        "\n",
        "# We convert every token id to its associated string, but find the special character ▁ which indicates the beginning of a word.\n",
        "# Note that very common words are represented by a single token, while others are split into subunits due to the small vocab size.\n",
        "# Also note that †he tokenizer already adds special tokens to the beginning and end of the sentence.\n",
        "decoded_sequence = [target_tokenizer.decode(token) for token in tokenizer_output[\"input_ids\"]]\n",
        "print(\"Tokens:\", decoded_sequence)\n",
        "\n",
        "# By replacing the special character ▁ with whitespace, we can reconstruct a legibile sentence,\n",
        "# which differs from the original example by special tokens, includings <unk> tokens, and minor whitespace differences.\n",
        "reconstructed = \"\".join(decoded_sequence).replace(\"▁\", \" \")\n",
        "print(\"Reconstructed sentence\", reconstructed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ui6m-oh1iIL"
      },
      "source": [
        "We now want to convert the entire dataset to token ids.\n",
        "Specifically, we want to use the tokenizers to create a dataset with\n",
        "features \"encoder_input_ids\" and \"decoder_input_ids\", which both have type `List[int]`\n",
        "and which will later be the inputs to our encoder-decoder model. We will implement this using the powerful `map` function. You can find its API reference [here](https://huggingface.co/docs/datasets/v2.10.0/en/package_reference/main_classes#datasets.Dataset.map)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "835d3d24c45042d5815eb29210eaf97e",
            "c966d56d63274cf48d7374eb883b1d67",
            "6b0888fad5504f5dbc88ff51e40696af",
            "294394dd26ed40178c55f5c647cec9d3",
            "cd73d443cd5f4f1d9f0ca807bcb74a74",
            "ab5ce00298824b2db2e5a05779ba8ba1",
            "831386bada174659a26f2eadb53ecc6d",
            "7e59bc2e9566407fab71956ad510f2c7",
            "b287d3e19e5f457cbd6bec68822c0590",
            "5613ad4441e84683aa07646e8448af12",
            "f7cddb1dee2b432eb668b986edca502a",
            "79f74e81239440da8834d636a518695a",
            "536a65edd1c04a33bedcb308777aced6",
            "d10b305d26b24b198949e06d9d43ffc1",
            "6eed8490a89e45e29d8de693f8a72cd1",
            "9b6cf07e8351438fbbfe9302fa37a622",
            "d959144845e749fcbe7deef7065c72dc",
            "a592f3a7e7a3461fa31a3fc0293e3c7a",
            "ec8045c5c9774e09a318bac5a50c57c3",
            "3cad858bf52d41b288792ff4e12d9b99",
            "d908d752459847bab9fe66e889e000f0",
            "3444fc472222441d88f36a21bc2daf9f",
            "72ad1817692c40c78060c6c570e77eaa",
            "f17bcd37b54f4b10aecbf0b7c627a77c",
            "835062f8dc29431496d714cd09001f85",
            "b2f8f503f2e345d7b1682bcf42f0c9f2",
            "e357a55ddf4f492caba77dec0b1d2946",
            "ff414e729b9a406bbe29aab8b8ca0b65",
            "08fd3a4beaa744e78e7029e9766cb31f",
            "bd2b8d43a32049e794e8bafc2cdbc3fd",
            "6bbe078bec8a486fb902a6eab83cc78f",
            "64b7c898d0ae47108131e5c455bf2398",
            "c4d6e58f4f274e4693039be4e5c66db8"
          ]
        },
        "id": "XPb6HpAH1iIL",
        "outputId": "996b14d9-1a9c-4fdd-af89-8d4c57cfc05b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "835d3d24c45042d5815eb29210eaf97e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8701 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79f74e81239440da8834d636a518695a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/485 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72ad1817692c40c78060c6c570e77eaa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/486 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from typing import Dict, List\n",
        "\n",
        "def map_example(example: Dict[str, str]) -> Dict[str, List[int]]:\n",
        "    # TODO: Tokenize the source and target text for an entry in the parallel dataset\n",
        "    # and return a dictionary with the keys \"encoder_input_ids\" and \"decoder_input_ids\".\n",
        "    # You can use `source_tokenizer` and `target_tokenizer`\n",
        "    encoder_input_ids = source_tokenizer(example['text_fr'])\n",
        "    encoder_input_ids=encoder_input_ids['input_ids']\n",
        "    decoder_input_ids = target_tokenizer(example['text_en'])\n",
        "    decoder_input_ids=decoder_input_ids['input_ids']\n",
        "    return {'encoder_input_ids':encoder_input_ids, 'decoder_input_ids':decoder_input_ids}\n",
        "\n",
        "\n",
        "\n",
        "# When mapped is applied to the DatasetDict object, it will apply `map` separately to each split.\n",
        "tokenized_datasets = raw_text_datasets.map(map_example, batched=False)\n",
        "\n",
        "# The `remove_columns` removes the existing text features from the new dataset, as they are no longer needed.\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(raw_text_datasets.column_names[\"train\"])\n",
        "\n",
        "# Sanity checks on the new dataset\n",
        "assert set(tokenized_datasets.column_names[\"train\"]) == {\"decoder_input_ids\", \"encoder_input_ids\"}\n",
        "assert len(tokenized_datasets[\"train\"]) == len(raw_text_datasets[\"train\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7dfDPzSb3kk"
      },
      "source": [
        "# Debug Check after Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co6QDFdPb1EM",
        "outputId": "0c56e5e0-7af2-4716-972b-cadca3efcf85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary of splits: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['encoder_input_ids', 'decoder_input_ids'],\n",
            "        num_rows: 8701\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['encoder_input_ids', 'decoder_input_ids'],\n",
            "        num_rows: 485\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['encoder_input_ids', 'decoder_input_ids'],\n",
            "        num_rows: 486\n",
            "    })\n",
            "})\n",
            "First training example: {'encoder_input_ids': [1, 47, 60, 1449, 36, 2], 'decoder_input_ids': [1, 37, 42, 1044, 35, 2]}\n"
          ]
        }
      ],
      "source": [
        "print(\"Summary of splits:\", tokenized_datasets)\n",
        "print(\"First training example:\", tokenized_datasets[\"train\"][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3qPsuS71iIL"
      },
      "source": [
        "## Transformer model for NMT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R90j2WL61iIM"
      },
      "source": [
        "We will now implement a encoder-decoder transformer model.\n",
        "We already provide code for the Feedforward Layers and Transformer Blocks, but you will have to implement the MultiHeadAttention and Embedding layer from scratch, as well as registering all the layers in the final EncoderDecoderModel. Pay attention to doc-strings and typing information to understand the context and purpose of each missing code block!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nVjxNtLz1iIM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import math\n",
        "from typing import Optional, Dict, List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pMQHadt1iIM"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 hidden_size: int,\n",
        "                 num_attention_heads: int,\n",
        "                 is_causal_attention: bool = False,\n",
        "                 is_cross_attention: bool = False):\n",
        "        \"\"\"Defines a flexible multi-head attention layer.\n",
        "\n",
        "        This layer should define parameters for the query, key and value projections, as well as the output projection,\n",
        "        and implement the following steps:\n",
        "        (1) Project the input vectors using query projection and key projection matrices.\n",
        "        (2) Compute the head-wise attention scores scaled by 1/sqrt(head_dim)\n",
        "        (3) Perform appropriate masking to the attention scores using key_padding_mask and optionally causal attention.\n",
        "        (4) Normalize the head-wise attention scores using softmax.\n",
        "        (5) Compute the value projections and then aggregate using the normalized attention scores.\n",
        "        (6) Use the output projection to obtain the final output vectors.\n",
        "        When is_cross_attention is True, the key and value projections are computed from the encoder outputs.\n",
        "        Note that we do not use attention weight dropout in this implementation.\n",
        "\n",
        "        Args:\n",
        "            hidden_size: The dimensionality of the input vectors.\n",
        "            num_attention_heads: The number of attention heads.\n",
        "            is_causal_attention: Whether to use causal masking,\n",
        "                    where tokens cannot attend to the future tokens on their right.\n",
        "            is_cross_attention: Whether to use cross attention,\n",
        "                    where we use different inputs for the key/value vs. query vectors.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        assert hidden_size % num_attention_heads == 0, \"The hidden size must be divisible by the number of attention heads.\"\n",
        "        self.head_dim = hidden_size // num_attention_heads  # embedding dimension of query and key vectors per head\n",
        "\n",
        "\n",
        "\n",
        "        # TODO Initialize the module and its parameters here.\n",
        "        # This module should be able to handle both full self-attention, causal masked self-attention and cross-attention.\n",
        "        # IMPORTANT: You are not allowed to use `nn.MultiheadAttention` or `nn.functional.scaled_dot_product_attention`!\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_heads = num_attention_heads\n",
        "        # Bias equals False 34an nbayen enena 2arena el documentation we m5alyenha matrix multiplication bas !!!!!!!! (https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
        "        self.query_matrix = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        self.value_matrix = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        self.key_matrix = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "        self.output_matrix = nn.Linear(hidden_size, hidden_size, bias=False)#concat multihead output gets multiplicated to it to get attention output\n",
        "        self.is_causal_attention = is_causal_attention\n",
        "        self.is_cross_attention = is_cross_attention\n",
        "\n",
        "\n",
        "    def causal_attention_mask(self,\n",
        "                              sequence_length: int,\n",
        "                              device: Optional[torch.device] = None) -> torch.FloatTensor:\n",
        "        \"\"\"Return a Float tensor that can be added to the (un-normalized) attention scores for causal masking.\n",
        "\n",
        "        Args:\n",
        "            sequence_length: width and height of the attention mask tensor.\n",
        "            device: which torch device the resulting tensor should be on (important if you use GPU).\n",
        "\n",
        "        Returns:\n",
        "            A Float tensor of shape (1, 1, sequence_length, sequence_length) on device `device`,\n",
        "            where the entries above the diagonal contain large negative values,\n",
        "            which means that a query at position i can't attend to a key at position j>i.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO Implement the forward function.\n",
        "        # IMPORTANT: For full credit, you should not use python loops.\n",
        "        #\n",
        "        # Hint 1: You can pick an arbitrary large value (e.g., -10^{6}), but note that\n",
        "        #         using `float(\"-inf\")` might lead to numerical issues and 'nan' values during training.\n",
        "        #\n",
        "        # Hint 2: Useful pytorch functions for this are `torch.arange` or `torch.triu`.\n",
        "        #\n",
        "        # Hint 3: You can move the tensor you create to a device by calling `tensor.to(device)`\n",
        "        #\n",
        "        # You should use this function in `forward` and use the returned tensor to implement causal masking\n",
        "        # by adding it to the un-normalized attention scores of shape (batch_size, num_heads, sequence_length, sequence_length),\n",
        "        # as torch will handle broadcasting and expand the first two dimensions to batch size and num_heads.\n",
        "        #\n",
        "        # You will the masking tensor to be on the same device as the attention scores's device,\n",
        "        # which you can via the attribute `tensor.device`.\n",
        "\n",
        "        #Create Upper Triangular matrix\n",
        "        mask = torch.triu(torch.full((sequence_length, sequence_length), -1e6), diagonal=1)\n",
        "\n",
        "        #Add 1,1 dimensions to beginning and move to device\n",
        "        return mask.unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "                hidden_states: torch.FloatTensor,\n",
        "                key_padding_mask: torch.BoolTensor,\n",
        "                encoder_outputs: Optional[torch.FloatTensor] = None) -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n",
        "        \"\"\"Computes scaled dot-product attention and returns the output of the attention layer.\n",
        "\n",
        "        Args:\n",
        "            hidden_states: Tensor of shape (batch_size, sequence_length, hidden_size) - the input vectors to the layer.\n",
        "            key_padding_mask: Tensor of shape (batch_size, sequence_length) indicating which tokens are padding tokens.\n",
        "                    A `True` entry means that this token should be ignored for the purpose of attention.\n",
        "                    In the case of cross-attention, the tensor has shape (batch_size, encoder_sequence_length).\n",
        "            encoder_outputs: Optional tensor of shape (batch_size, encoder_sequence_length, hidden_size).\n",
        "                    The output vectors of the encoder and only passed if the layer performs cross-attention.\n",
        "\n",
        "        Returns:\n",
        "            A (layer_output, attention_weights) where layer_output is a tensor of shape (batch_size, sequence_length, hidden_size)\n",
        "            and attention_weights are the normalized attention scores in the form of\n",
        "            a tensor of shape (batch_size, num_attention_heads, number_of_query_tokens, number_of_key_tokens).\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO Implement the forward function.\n",
        "        # IMPORTANT: For full credit, you should not use python loops. Furthermore,\n",
        "        #            you are not allowed to use `nn.MultiheadAttention` or `nn.functional.scaled_dot_product_attention`!\n",
        "        #\n",
        "        # Hint 1: Use `torch.reshape` to add a new axis for the attention head,\n",
        "        #         which will allow you to process all attention heads in parallel.\n",
        "        #\n",
        "        # Hint 2: You can use `torch.transpose` to swap the order of two axes,\n",
        "        #         As the attention head dimension should be next to the batch size,\n",
        "        #         see the shape of the output attention weights.\n",
        "        #\n",
        "        # Hint 3: `torch.bmm(matrix1, matrix2)` is useful for computing batched matrix multiplications\n",
        "        #         If matrix1 has shape (B, M, N) and matrix2 has shape (B, N, P),\n",
        "        #         it performs `B` matrix multiplications and outputs a tensor of shape (B, M, P).\n",
        "        #         Alternatively, `torch.einsum` should be very useful.\n",
        "        #         (We really encourage you to check out the documentation of `torch.einsum`,\n",
        "        #         it can really make your life easier here.)\n",
        "\n",
        "\n",
        "        #Get Device (Assuming hidden_states tensor is on correct device)\n",
        "        device = hidden_states.device\n",
        "\n",
        "        #Get Dimensions\n",
        "        batch_size = hidden_states.shape[0]\n",
        "        seq_length = hidden_states.shape[1]\n",
        "\n",
        "\n",
        "        # Calculate Q, K, V\n",
        "        queries = self.query_matrix(hidden_states) # Shape : (batch_size, sequence_length, hidden_size)\n",
        "\n",
        "        if self.is_cross_attention:\n",
        "          values = self.value_matrix(encoder_outputs) # Shape : (batch_size, sequence_length, hidden_size)\n",
        "          keys = self.key_matrix(encoder_outputs) # Shape : (batch_size, sequence_length, hidden_size)\n",
        "          seq_length2 = encoder_outputs.shape[1] # In case of cross attention it will be the encoder's sequence length\n",
        "        else:\n",
        "          values = self.value_matrix(hidden_states) # Shape : (batch_size, sequence_length, hidden_size)\n",
        "          keys = self.key_matrix(hidden_states) # Shape : (batch_size, sequence_length, hidden_size)\n",
        "          seq_length2 = seq_length # If no cross attention is used will be same as sequence length\n",
        "\n",
        "\n",
        "        # Add New Axis for attention heads (Change last dimension from hidden_size to num_heads x head_dim)\n",
        "        #Each head in multihead attention gets a part of the embedding for each word in the sentence\n",
        "        queries =  queries.reshape(batch_size, seq_length, self.num_heads, self.head_dim)\n",
        "        values = values.reshape(batch_size, seq_length2, self.num_heads, self.head_dim)\n",
        "        keys = keys.reshape(batch_size, seq_length2, self.num_heads, self.head_dim)\n",
        "\n",
        "\n",
        "        # Change dimensions from: (batch_size, seq_length/seq_length2, num_heads, head_dim) to (batch_size, num_heads, seq_length/seq_length2, head_dim)\n",
        "        # Transpose Dimension 1 and Dimension 2\n",
        "        queries = queries.transpose(1,2) # Shape : (batch_size, num_heads, seq_length, head_dim)\n",
        "        values = values.transpose(1,2) # Shape : (batch_size, num_heads, seq_length2, head_dim)\n",
        "        keys = keys.transpose(1,2) # Shape : (batch_size, num_heads, seq_length2, head_dim)\n",
        "\n",
        "        #For keys, we need to also swap seq_length2 and head_dim for the bmm for the attention scores\n",
        "        keys = keys.transpose(2, 3) # Shape : (batch_size, num_heads, head_dim, seq_length2)\n",
        "        #3tlt hna\n",
        "        #Calculate Attention Scores\n",
        "        attention_scores = torch.matmul(queries, keys) / math.sqrt(self.head_dim) # (batch_size, num_heads, seq_length, seq_length2)\n",
        "\n",
        "\n",
        "        #Apply causal Mask\n",
        "        if self.is_causal_attention:\n",
        "          causal_mask = self.causal_attention_mask(seq_length, device)\n",
        "          attention_scores += causal_mask\n",
        "\n",
        "        #Apply Padding Mask\n",
        "        '''\n",
        "        1- key_padding_mask has shape: (batch_size, seq_length2).\n",
        "        2- Convert to float (True/False) -> (1.0/0.0)\n",
        "        3- Multiply by 1e-6. (1.0/0.0) -> (-1e6/0.0) -1e6 where padding tokens are\n",
        "        4- Then we reshape it to be: (batch_size, 1, 1, seq_length2)\n",
        "        5- Which is broadcastable to: (batch_size, num_heads, seq_length, seq_length2) for attention_scores\n",
        "\n",
        "        '''\n",
        "        key_padding_mask = key_padding_mask.to(torch.float) * -1e6 # 1e-6 where pad = True and 0 where pad = False\n",
        "        key_padding_mask = key_padding_mask.reshape(batch_size, 1, 1, seq_length2)\n",
        "        attention_scores += key_padding_mask\n",
        "\n",
        "\n",
        "        # Apply Softmax to last dimension\n",
        "        attention_scores = torch.nn.functional.softmax(attention_scores, dim=-1) # Shape: (batch_size, num_heads, seq_length, seq_length2)\n",
        "\n",
        "\n",
        "        # Multiply by value vectors and add\n",
        "        '''\n",
        "        Attention Scores: (batch_size, num_heads, seq_length, seq_length2)\n",
        "        Values Vectors: (batch_size, num_heads, seq_length2, head_dim)\n",
        "        BMM Result: (batch_size, num_heads, seq_length, head_dim)\n",
        "        '''\n",
        "\n",
        "        attention_outputs = torch.matmul(attention_scores, values) # (batch_size, num_heads, seq_length, head_dim)\n",
        "\n",
        "        '''\n",
        "        For attention weights:\n",
        "        Convert (batch_size, num_heads, seq_length, head_dim) to (batch_size, seq_length, num_heads, head_dim) by transposing\n",
        "        Then reshape to be: (batch_size, seq_length, num_heads * head_dim) = (batch_size, seq_length, hidden_size)\n",
        "        '''\n",
        "        attention_outputs = attention_outputs.transpose(1, 2)\n",
        "        attention_outputs = attention_outputs.reshape(batch_size, seq_length, self.hidden_size)\n",
        "\n",
        "\n",
        "        # Multiply Attention Outputs with output matrix\n",
        "        attention_outputs = self.output_matrix(attention_outputs) # (batch_size, num_heads, seq_length, head_dim)\n",
        "\n",
        "\n",
        "        return (attention_outputs, attention_scores)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv8Ob5OGA8dK"
      },
      "source": [
        "# Multi Head Attention Debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9NSVh4hA793",
        "outputId": "f25ee19d-33e2-44e7-8e0c-a385fef13ee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[       0., -1000000., -1000000., -1000000., -1000000.],\n",
            "          [       0.,        0., -1000000., -1000000., -1000000.],\n",
            "          [       0.,        0.,        0., -1000000., -1000000.],\n",
            "          [       0.,        0.,        0.,        0., -1000000.],\n",
            "          [       0.,        0.,        0.,        0.,        0.]]]])\n",
            "torch.Size([1, 1, 5, 5])\n"
          ]
        }
      ],
      "source": [
        "# Test torch.triu\n",
        "n = 5\n",
        "negative_num = -1e6\n",
        "device = 'cpu'\n",
        "causal_mask = torch.triu(torch.full((n, n), negative_num), diagonal=1).unsqueeze(0).unsqueeze(0).to(device)\n",
        "print(causal_mask)\n",
        "print(causal_mask.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9DqNv5-et0W",
        "outputId": "b38c30ed-26c8-4275-e0e7-78974fe069f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False]])\n",
            "tensor([[1.0000e-06, 0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e-06, 0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e-06, 0.0000e+00, 0.0000e+00]])\n"
          ]
        }
      ],
      "source": [
        "key_padding_mask = torch.randint(0, 2, (3,3), dtype=torch.bool)\n",
        "\n",
        "print(key_padding_mask)\n",
        "print(key_padding_mask.to(torch.float)*1e-6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNhiLcSw1iIM"
      },
      "source": [
        "Before we move on to the other modules, you should implement a sanity check for your attention implementation:\n",
        "1. We check the dimensions of the output of the layer and\n",
        "2. We plot the attention weights to some toy embedding inputs.\n",
        "We assume that the last token in the encoder and the last two tokens in the decoder are pad tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "epu_wgGi1iIM",
        "outputId": "f8821b5b-56a2-4142-e58a-475628cff73f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "embed_dim = 8\n",
        "num_heads = 2\n",
        "batch_size = 1\n",
        "encoder_seq_length = 5\n",
        "decoder_seq_length = 7\n",
        "\n",
        "encoder_outputs = torch.randn(batch_size, encoder_seq_length, embed_dim)\n",
        "decoder_inputs = torch.randn(batch_size, decoder_seq_length, embed_dim)\n",
        "\n",
        "encoder_padding_mask = torch.zeros(batch_size, encoder_seq_length, dtype=torch.bool)\n",
        "encoder_padding_mask[:, -1] = True # The last encoder token is a padding tokens\n",
        "\n",
        "decoder_padding_mask = torch.zeros(batch_size, decoder_seq_length, dtype=torch.bool)\n",
        "decoder_padding_mask[:, -2:] = True # The last two decoder tokens are padding token\n",
        "\n",
        "\n",
        "cross_attention = MultiHeadAttention(embed_dim, num_heads, is_cross_attention=True)\n",
        "causal_attention = MultiHeadAttention(embed_dim, num_heads, is_causal_attention=True)\n",
        "\n",
        "cross_attention_out, cross_attention_weights = cross_attention(decoder_inputs, encoder_padding_mask, encoder_outputs)\n",
        "causal_attention_out, causal_attention_weights = causal_attention(decoder_inputs, decoder_padding_mask)\n",
        "\n",
        "# Make sure your outputs have the right shapes\n",
        "assert cross_attention_out.shape == (batch_size, decoder_seq_length, embed_dim)\n",
        "assert cross_attention_weights.shape == (batch_size, num_heads, decoder_seq_length, encoder_seq_length)\n",
        "assert causal_attention_out.shape == (batch_size, decoder_seq_length, embed_dim)\n",
        "assert causal_attention_weights.shape == (batch_size, num_heads, decoder_seq_length, decoder_seq_length)\n",
        "\n",
        "# Check that the attention weights are normalized\n",
        "assert torch.isclose(cross_attention_weights.sum(dim=-1), torch.tensor(1.0)).all()\n",
        "assert torch.isclose(causal_attention_weights.sum(dim=-1), torch.tensor(1.0)).all()\n",
        "\n",
        "# Check if the attention masking works\n",
        "assert torch.isclose(cross_attention_weights[:,:,:,-1], torch.tensor(0.0)).all()\n",
        "assert torch.isclose(causal_attention_weights[:,:,:,-2:], torch.tensor(0.0)).all()\n",
        "assert torch.isclose(causal_attention_weights[:,:,2,3:], torch.tensor(0.0)).all()\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_attention_matrix(attention_matrix, title):\n",
        "    \"\"\"Creates a new figure and plots the normalized attention weights as a heatmap.\n",
        "\n",
        "    This should provide a colorbar for the scale of the heatmap and label the axes \"query token position\" and \"key token position\".\n",
        "\n",
        "    Args:\n",
        "        attention_matrix: A numpy array of shape (number_of_query_tokens, number_of_key_tokens)\n",
        "        title: The title of the plot.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(attention_matrix, cmap='viridis', aspect='auto')\n",
        "    plt.colorbar(label='Attention Weight')\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Key Token Position')\n",
        "    plt.ylabel('Query Token Position')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_attention_matrix(cross_attention_weights[0,0].detach().numpy(), \"cross-attention, head 1\")\n",
        "plot_attention_matrix(cross_attention_weights[0,1].detach().numpy(), \"cross-attention, head 2\")\n",
        "plot_attention_matrix(causal_attention_weights[0,0].detach().numpy(), \"causal self-attention, head 1\")\n",
        "plot_attention_matrix(causal_attention_weights[0,1].detach().numpy(), \"causal self-attention, head 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d86pBrD71iIN"
      },
      "outputs": [],
      "source": [
        "class TransformerEmbeddings(nn.Module):\n",
        "    def __init__(self, vocab_size: int, hidden_size: int, max_sequence_length: int):\n",
        "        \"\"\"Defines the embedding layer with learnt positional embeddings.\n",
        "\n",
        "        This layer defines both the token embeddings and positional embeddings,\n",
        "        which are added together to form the final embedding.\n",
        "\n",
        "        Args:\n",
        "            vocab_size: The size of the vocabulary,\n",
        "                    used to define the size of the token embedding table.\n",
        "            hidden_size: The dimensionality of the embedding space for both token embeddings and positional embeddings.\n",
        "            max_sequence_length: The maximum sequence length of the input sequences,\n",
        "                    used to define the size of the position embedding table.\n",
        "\n",
        "        Note that this implementation does not use dropout on the embeddings\n",
        "        and uses learnt positional embeddings instead of sinusoidal embeddings.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO Initialize the module and its parameters here.\n",
        "        # You should use `nn.Embedding` for both token embeddings and positional embeddings\n",
        "        self.embeddings=nn.Embedding(vocab_size,hidden_size)\n",
        "        self.posEmbeddings=nn.Embedding(max_sequence_length,hidden_size)#learnt postional embedding\n",
        "\n",
        "        #raise NotImplementedError(\"The __init__ function in TransformerEmbeddings is not implemented yet.\")\n",
        "\n",
        "    def compute_logits(self, decoder_output: torch.FloatTensor) -> torch.FloatTensor:\n",
        "        \"\"\"Computes the logits for the next token prediction given the decoder output.\n",
        "\n",
        "        Args:\n",
        "            decoder_output: Tensor of shape (batch_size, sequence_length, hidden_size) - the output of the decoder.\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape (batch_size, sequence_length, vocab_size) containing the logits for the next token prediction.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO Implement this function\n",
        "        # Hint: you can access the weight parameter matrix via .weight of an nn.Embedding module:\n",
        "        # Example:\n",
        "        # ```embeddings = nn.Embedding(num_embeddings, embedding_dim)\n",
        "        # assert list(embeddings.weight.shape) == [num_embeddings, embedding_dim]```\n",
        "        # torch.matmul or F.linear may also be useful here.\n",
        "        self.logits = torch.matmul(decoder_output, self.embeddings.weight.T)\n",
        "        return self.logits\n",
        "\n",
        "       # raise NotImplementedError(\"The compute_logits function in TransformerEmbeddings is not implemented yet.\")\n",
        "\n",
        "    def forward(self, input_ids: torch.LongTensor) -> torch.FloatTensor:\n",
        "        \"\"\"Computes the embeddings for the input tokens.\n",
        "\n",
        "        Args:\n",
        "            input_ids: Tensor of shape (batch_size, sequence_length) containing the input token ids.\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape (batch_size, sequence_length, hidden_size) containing\n",
        "                    the sum of token embeddings and position embeddings for the input tokens.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO Implement the forward pass of the embedding layer.\n",
        "        # IMPORTANT: For full credit, you should not use python loops!\n",
        "        #myEmbeddings=self.embeddings(input_ids)#shape (batchsize,sequenceLength,demb)\n",
        "        #posEmbeddings=self.posEmbeddings(torch.arange(input_ids.shape[1]))#get positional embedding to each word shape(batchsize,sequence_length,demb)\n",
        "        #return myEmbeddings+posEmbeddings\n",
        "        # Compute token embeddings\n",
        "        token_embeddings = self.embeddings(input_ids)#(batch_size, sequence_length, hidden_size)\n",
        "        # Compute position embeddings\n",
        "        batch_size, sequence_length = input_ids.shape\n",
        "        position_ids = torch.arange(sequence_length, dtype=torch.int, device=input_ids.device)#[0 to sequence length]\n",
        "        # device=input_ids.device ensures that output tensor on the same oricessor as inputs_id\n",
        "        position_ids = position_ids.unsqueeze(0).expand(batch_size, sequence_length)#change tensor size to (batchSize,sequence length)\n",
        "        position_embeddings = self.posEmbeddings(position_ids)\n",
        "\n",
        "        # Sum token embeddings and position embeddings\n",
        "        embeddings = token_embeddings + position_embeddings\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "        #raise NotImplementedError(\"The forward function in TransformerEmbeddings is not implemented yet.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFW-eNNB1iIN"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 hidden_size: int,\n",
        "                 intermediate_size: int,\n",
        "                 num_attention_heads: int,\n",
        "                 hidden_dropout_prob: float,\n",
        "                 is_decoder: bool = False):\n",
        "        \"\"\"Defines a single Transformer block, which can be either for the encoder or the decoder.\n",
        "\n",
        "        Args:\n",
        "            hidden_size: The dimensionality of the input and output vectors of this layer.\n",
        "            intermediate_size: The intermediate size of the feedforward layers.\n",
        "            num_attention_heads: The number of attention heads.\n",
        "            hidden_dropout_prob: The dropout probability for the hidden states.\n",
        "            is_decoder: Whether this block is part of the decoder.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.is_decoder = is_decoder\n",
        "        self.self_attention = MultiHeadAttention(hidden_size, num_attention_heads, is_causal_attention=is_decoder)\n",
        "        self.self_attention_layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        if is_decoder:\n",
        "            self.cross_attention = MultiHeadAttention(hidden_size, num_attention_heads, is_cross_attention=True)\n",
        "            self.cross_attention_layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(hidden_size, intermediate_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(intermediate_size, hidden_size),\n",
        "            nn.Dropout(hidden_dropout_prob))\n",
        "        self.feedforward_layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self,\n",
        "                hidden_states: torch.FloatTensor,\n",
        "                padding_mask: torch.BoolTensor,\n",
        "                encoder_outputs: Optional[torch.FloatTensor] = None,\n",
        "                encoder_padding_mask: Optional[torch.BoolTensor] = None) -> torch.FloatTensor:\n",
        "        \"\"\"Defines a single Transformer block, either for the encoder or the decoder.\n",
        "\n",
        "        Args:\n",
        "            hidden_states: Tensor of shape (batch_size, sequence_length, hidden_size) - the outputs from the previous layer.\n",
        "            padding_mask: Tensor of shape (batch_size, sequence_length) indicating which tokens are padding tokens.\n",
        "                    A `True` entry means that this token should be ignored for the purpose of attention.\n",
        "            encoder_outputs: Optional tensor of shape (batch_size, encoder_sequence_length, hidden_size),\n",
        "                    which are the output vectors of the encoder. This argument is only used by decoder blocks.\n",
        "            encoder_padding_mask: Optional tensor of shape (batch_size, encoder_sequence_length) indicating\n",
        "                    which encoder tokens are padding tokens. This argument is only used in decoder blocks.\n",
        "                    A `True` entry means that this token should be ignored for the purpose of attention.\n",
        "\n",
        "        \"\"\"\n",
        "        hidden_states = self.self_attention(hidden_states, padding_mask)[0] + hidden_states\n",
        "        hidden_states = self.self_attention_layer_norm(hidden_states)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            hidden_states = self.cross_attention(hidden_states, encoder_padding_mask, encoder_outputs)[0] + hidden_states\n",
        "            hidden_states = self.cross_attention_layer_norm(hidden_states)\n",
        "\n",
        "        hidden_states = self.feedforward(hidden_states) + hidden_states\n",
        "        hidden_states = self.feedforward_layer_norm(hidden_states)\n",
        "        return hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC_EQSQ51iIN"
      },
      "outputs": [],
      "source": [
        "class EncoderDecoderModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 source_vocab_size: int,\n",
        "                 target_vocab_size: int,\n",
        "                 hidden_size: int,\n",
        "                 intermediate_size: int,\n",
        "                 num_attention_heads: int,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 max_sequence_length: int,\n",
        "                 hidden_dropout_prob: float):\n",
        "        \"\"\"A encoder-decoder transformer model which can be used for NMT.\n",
        "\n",
        "        Args:\n",
        "            source_vocab_size: The size of the source vocabulary.\n",
        "            target_vocab_size: The size of the target vocabulary.\n",
        "            hidden_size: The dimensionality of all input and output embeddings.\n",
        "            intermediate_size: The intermediate size in the feedforward layers.\n",
        "            num_attention_heads: The number of attention heads in each multi-head attention modules.\n",
        "            num_encoder_layers: The number of transformer blocks in the encoder.\n",
        "            num_decoder_layers: The number of transformer blocks in the decoder.\n",
        "            max_sequence_length: The maximum sequence length that this model can handle.\n",
        "            hidden_dropout_prob: The dropout probability in the hidden state in each block.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        # TODO Register the input embedding modules and the encoder and decoder blocks.\n",
        "        # You should use the TransformerBlock and TransformerEmbeddings sub-modules.\n",
        "        self.hidden_size=hidden_size\n",
        "\n",
        "        self.num_encoder_layers=num_encoder_layers\n",
        "        self.num_decoder_layers=num_decoder_layers\n",
        "        self.max_sequence_length=max_sequence_length\n",
        "        self.source_vocab_size=source_vocab_size\n",
        "        self.target_vocab_size=target_vocab_size\n",
        "        self.linear=nn.Linear(self.hidden_size, self.target_vocab_size,bias=False)#WO layer to conver output back\n",
        "        self.source_embeddings = TransformerEmbeddings(source_vocab_size, hidden_size, max_sequence_length)\n",
        "        self.target_embeddings = TransformerEmbeddings(target_vocab_size, hidden_size, max_sequence_length)\n",
        "        self.encoderlayers = nn.ModuleList([TransformerBlock(hidden_size, intermediate_size, num_attention_heads, hidden_dropout_prob) for _ in range(self.num_encoder_layers)])\n",
        "        self.decoderlayers = nn.ModuleList([TransformerBlock(hidden_size, intermediate_size, num_attention_heads, hidden_dropout_prob, is_decoder=True) for _ in range(self.num_decoder_layers)])\n",
        "        # Hint: Check out `nn.ModuleList` to register a variable number of sub-modules.\n",
        "\n",
        "       # raise NotImplementedError(\"The __init__ function is not implemented yet.\")\n",
        "\n",
        "    def forward_encoder(self, input_ids: torch.LongTensor, padding_mask: torch.BoolTensor) -> torch.FloatTensor:\n",
        "        \"\"\"Implement the forward pass of the encoder.\n",
        "\n",
        "        Args:\n",
        "            input_ids: tensor of shape (batch_size, sequence_length) containing the input token ids to the encoder.\n",
        "            padding_mask: tensor of shape (batch_size, sequence_length) indicating which encoder tokens are padding tokens (`True`)\n",
        "                    and should be ignored in self-attention computations.\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape (batch_size, sequence_length, hidden_size) containing the output embeddings of the encoder.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO Implement this function\n",
        "        embd = self.source_embeddings(input_ids)\n",
        "        for layer in self.encoderlayers:\n",
        "          embd=layer(embd,padding_mask)#pass output of each encoder to the next encoder\n",
        "        return (embd)\n",
        "\n",
        "\n",
        "\n",
        "       # raise NotImplementedError(\"The forward_encoder function is not implemented yet.\")\n",
        "\n",
        "    def forward_decoder(self,\n",
        "                        input_ids: torch.LongTensor,\n",
        "                        padding_mask: torch.BoolTensor,\n",
        "                        encoder_outputs: torch.FloatTensor,\n",
        "                        encoder_padding_mask: torch.BoolTensor) -> torch.FloatTensor:\n",
        "        \"\"\"Implement the forward pass of the decoder.\n",
        "\n",
        "        Args:\n",
        "            input_ids: Tensor of shape (batch_size, sequence_length) containing the input token ids to the decoder.\n",
        "            padding_mask: Tensor of shape (batch_size, sequence_length) indicating which decoder tokens are padding tokens (`True`)\n",
        "                    and should be ignored in self-attention computations.\n",
        "            encoder_outputs: Tensor of shape (batch_size, encoder_sequence_length, hidden_size) containing the output embeddings of the encoder.\n",
        "            encoder_padding_mask: Tensor of shape (batch_size, encoder_sequence_length) indicating which encoder tokens are padding tokens (`True`)\n",
        "                    and should be ignored in cross-attention computations.\n",
        "\n",
        "        Returns:\n",
        "            Tensor of shape (batch_size, sequence_length, target_vocabulary_size)\n",
        "            containing the logits for predicting the next token in the target sequence.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO Implement this function\n",
        "        embd = self.target_embeddings(input_ids)\n",
        "        for layer in self.decoderlayers:\n",
        "          embd=layer(embd,padding_mask,encoder_outputs,encoder_padding_mask)#pass output of each decoders to the next decoder\n",
        "\n",
        "        return self.target_embeddings.compute_logits(embd)\n",
        "\n",
        "        #raise NotImplementedError(\"The forward_decoder function has to be implemented.\")\n",
        "\n",
        "    def forward(self, encoder_input_ids, encoder_padding_mask, decoder_input_ids, decoder_padding_mask):\n",
        "        encoder_outputs = self.forward_encoder(encoder_input_ids, encoder_padding_mask)\n",
        "        decoder_logits = self.forward_decoder(decoder_input_ids, decoder_padding_mask, encoder_outputs, encoder_padding_mask)\n",
        "        return decoder_logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbf1FkZteHIW"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "In this section, we train the seq2seq model on the parallel tokenized corpus.\n",
        "Before you start training models, you should implement and test the model and its sub-modules, especially the attention.\n",
        "\n",
        "First, we implement a `collate` function, which takes a list of examples from the dataset and forms a batch,\n",
        "consisting of padded encoder and decoder input ids, as well as encoder and decoder padding masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VknfRSbb1iIN"
      },
      "outputs": [],
      "source": [
        "def collate_fn(examples: List[Dict[str, List[int]]]) -> Dict[str, torch.Tensor]:\n",
        "    \"\"\"Collates a list of variable length sequences from the dataset into a batch of pytorch tensors with padding.\"\"\"\n",
        "\n",
        "    encoder_sequence_length = max(len(example[\"encoder_input_ids\"]) for example in examples)\n",
        "    decoder_sequence_length = max(len(example[\"decoder_input_ids\"]) for example in examples)\n",
        "    batch_size = len(examples)\n",
        "\n",
        "    encoder_input_ids = torch.full((batch_size, encoder_sequence_length),\n",
        "                                   fill_value=source_tokenizer.pad_token_id,\n",
        "                                   dtype=torch.int64)\n",
        "\n",
        "    encoder_padding_mask = torch.ones((batch_size, encoder_sequence_length),\n",
        "                                      dtype=torch.bool)\n",
        "\n",
        "    decoder_input_ids = torch.full((batch_size, decoder_sequence_length),\n",
        "                                   fill_value=target_tokenizer.pad_token_id,\n",
        "                                   dtype=torch.int64)\n",
        "    decoder_padding_mask = torch.ones((batch_size, decoder_sequence_length),\n",
        "                                      dtype=torch.bool)\n",
        "\n",
        "    for i, example in enumerate(examples):\n",
        "        encoder_input_ids[i, :len(example[\"encoder_input_ids\"])] = torch.tensor(example[\"encoder_input_ids\"])\n",
        "        encoder_padding_mask[i, :len(example[\"encoder_input_ids\"])] = False\n",
        "\n",
        "        decoder_input_ids[i, :len(example[\"decoder_input_ids\"])] = torch.tensor(example[\"decoder_input_ids\"])\n",
        "        decoder_padding_mask[i, :len(example[\"decoder_input_ids\"])] = False\n",
        "\n",
        "    return {\"encoder_input_ids\": encoder_input_ids,\n",
        "            \"encoder_padding_mask\": encoder_padding_mask,\n",
        "            \"decoder_input_ids\": decoder_input_ids,\n",
        "            \"decoder_padding_mask\": decoder_padding_mask}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgp3PZL21iIN"
      },
      "source": [
        "Next, we provide a simple training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeZgvg2VkRQd"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def compute_loss_per_token(model, batch):\n",
        "    logits = model(**batch)\n",
        "\n",
        "    valid_label_mask = ~(batch[\"decoder_padding_mask\"][:,1:])\n",
        "    labels = batch[\"decoder_input_ids\"][:,1:][valid_label_mask]\n",
        "    logits = logits[:,:-1][valid_label_mask]\n",
        "\n",
        "    return F.cross_entropy(logits, labels, reduction='none')\n",
        "\n",
        "\n",
        "def evaluate_perplexity(model, dataset, batch_size=32, device=\"cpu\"):\n",
        "    model.eval()\n",
        "\n",
        "    dev_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    num_tokens = loss_sum = 0\n",
        "\n",
        "    # no_grad() signals backend to throw away all gradients\n",
        "    with torch.no_grad():\n",
        "        for batch in dev_loader:\n",
        "            # Move tensors in batch to device\n",
        "            for key in batch:\n",
        "                batch[key] = batch[key].to(device)\n",
        "\n",
        "            token_losses = compute_loss_per_token(model, batch)\n",
        "\n",
        "            loss_sum += token_losses.sum()\n",
        "            num_tokens += token_losses.numel()\n",
        "\n",
        "        dev_ppl = (loss_sum / num_tokens).exp().cpu().item()\n",
        "    return dev_ppl\n",
        "\n",
        "\n",
        "def train(model, training_dataset, validation_dataset,\n",
        "          batch_size=32, lr=1e-3, max_epoch=10, log_every=10, valid_niter=100,\n",
        "          model_path=\"model.pt\"):\n",
        "    model.train()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('Use device: %s' % device)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    epoch = global_step = loss_sum = num_tokens = num_examples = 0\n",
        "    best_valid_perplexity = float('inf')\n",
        "    train_time = begin_time = time.time()\n",
        "    print('Beginning maximum likelihood training')\n",
        "\n",
        "\n",
        "    while True:\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            training_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "        epoch += 1\n",
        "        batches_per_epoch = len(train_loader)\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            global_step += 1\n",
        "\n",
        "            # Move tensors in batch to device\n",
        "            for key in batch:\n",
        "                batch[key] = batch[key].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            token_losses = compute_loss_per_token(model, batch)\n",
        "            total_loss = token_losses.sum()\n",
        "\n",
        "            loss = total_loss / batch_size\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_sum += total_loss.cpu().item()\n",
        "            num_tokens += token_losses.numel()\n",
        "            num_examples += batch_size\n",
        "\n",
        "            if global_step % log_every == 0:\n",
        "                average_loss = loss_sum / num_examples\n",
        "                average_ppl = math.exp(loss_sum / num_tokens)\n",
        "                print(f\"epoch {epoch} ({i}/{batches_per_epoch}) | step {global_step} | \"\n",
        "                      f\"avg_nll={average_loss:.2f} avg_ppl={average_ppl:.2f} \"\n",
        "                      f\"speed={num_tokens / (time.time() - train_time):.2f} words/sec \"\n",
        "                      f\"time_elapsed={time.time() - begin_time:.2f} sec\")\n",
        "\n",
        "                train_time = time.time()\n",
        "                loss_sum = num_tokens = num_examples = 0.0\n",
        "            if global_step % valid_niter == 0:\n",
        "\n",
        "                print('Begin validation ...')\n",
        "                dev_perplexity = evaluate_perplexity(model, validation_dataset, batch_size=batch_size, device=device)\n",
        "\n",
        "                print(f\"validation: step {global_step} | dev_ppl={dev_perplexity}\")\n",
        "\n",
        "                if dev_perplexity < best_valid_perplexity:\n",
        "                    best_valid_perplexity = dev_perplexity\n",
        "                    print(f\"epoch {epoch} step {global_step}: save currently the best model to '{model_path}'\")\n",
        "                    torch.save(model.state_dict(), model_path)\n",
        "                    torch.save(optimizer.state_dict(), model_path + '.optim')\n",
        "                model.train()\n",
        "\n",
        "        if epoch == max_epoch:\n",
        "            print('Reached maximum number of epochs')\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8NLae1r1iIO"
      },
      "source": [
        "Let's train a relatively small model architecture for 15 epochs.\n",
        "With a reasonable implementation, this should take about 16 minutes on CPU / 3 minutes on GPU and we should achieve a validation perplexity of below 10!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j8KNRx21iIO",
        "outputId": "ad695064-14bb-4437-ecda-8eb6b97d9af3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "13\n",
            "13\n",
            "14\n",
            "12\n",
            "13\n",
            "14\n",
            "epoch 2 (107/272) | step 380 | avg_nll=27.89 avg_ppl=45.30 speed=3915.86 words/sec time_elapsed=31.77 sec\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "epoch 2 (117/272) | step 390 | avg_nll=27.41 avg_ppl=44.94 speed=4054.52 words/sec time_elapsed=32.34 sec\n",
            "14\n",
            "12\n",
            "15\n",
            "12\n",
            "16\n",
            "15\n",
            "12\n",
            "15\n",
            "13\n",
            "13\n",
            "epoch 2 (127/272) | step 400 | avg_nll=27.49 avg_ppl=42.59 speed=4310.33 words/sec time_elapsed=32.89 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 400 | dev_ppl=36.24283218383789\n",
            "epoch 2 step 400: save currently the best model to 'model.pt'\n",
            "14\n",
            "13\n",
            "15\n",
            "12\n",
            "12\n",
            "14\n",
            "15\n",
            "13\n",
            "15\n",
            "16\n",
            "epoch 2 (137/272) | step 410 | avg_nll=26.60 avg_ppl=40.79 speed=2468.68 words/sec time_elapsed=33.82 sec\n",
            "13\n",
            "14\n",
            "14\n",
            "12\n",
            "14\n",
            "13\n",
            "14\n",
            "12\n",
            "17\n",
            "14\n",
            "epoch 2 (147/272) | step 420 | avg_nll=27.05 avg_ppl=40.94 speed=3890.09 words/sec time_elapsed=34.42 sec\n",
            "17\n",
            "14\n",
            "15\n",
            "12\n",
            "12\n",
            "14\n",
            "12\n",
            "11\n",
            "15\n",
            "14\n",
            "epoch 2 (157/272) | step 430 | avg_nll=26.37 avg_ppl=37.59 speed=2738.95 words/sec time_elapsed=35.26 sec\n",
            "13\n",
            "16\n",
            "12\n",
            "16\n",
            "14\n",
            "13\n",
            "15\n",
            "14\n",
            "12\n",
            "13\n",
            "epoch 2 (167/272) | step 440 | avg_nll=26.65 avg_ppl=37.94 speed=2745.95 words/sec time_elapsed=36.12 sec\n",
            "16\n",
            "14\n",
            "14\n",
            "13\n",
            "13\n",
            "15\n",
            "13\n",
            "17\n",
            "13\n",
            "14\n",
            "epoch 2 (177/272) | step 450 | avg_nll=26.29 avg_ppl=35.67 speed=2612.76 words/sec time_elapsed=37.02 sec\n",
            "12\n",
            "13\n",
            "14\n",
            "13\n",
            "15\n",
            "15\n",
            "12\n",
            "14\n",
            "13\n",
            "15\n",
            "epoch 2 (187/272) | step 460 | avg_nll=24.17 avg_ppl=29.90 speed=2482.04 words/sec time_elapsed=37.94 sec\n",
            "13\n",
            "14\n",
            "14\n",
            "12\n",
            "14\n",
            "14\n",
            "13\n",
            "15\n",
            "12\n",
            "14\n",
            "epoch 2 (197/272) | step 470 | avg_nll=24.98 avg_ppl=31.05 speed=3157.21 words/sec time_elapsed=38.68 sec\n",
            "13\n",
            "13\n",
            "14\n",
            "12\n",
            "11\n",
            "13\n",
            "12\n",
            "15\n",
            "12\n",
            "15\n",
            "epoch 2 (207/272) | step 480 | avg_nll=25.21 avg_ppl=33.19 speed=3728.11 words/sec time_elapsed=39.30 sec\n",
            "13\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "11\n",
            "13\n",
            "13\n",
            "14\n",
            "16\n",
            "epoch 2 (217/272) | step 490 | avg_nll=25.34 avg_ppl=33.11 speed=3960.32 words/sec time_elapsed=39.88 sec\n",
            "13\n",
            "13\n",
            "13\n",
            "14\n",
            "12\n",
            "15\n",
            "12\n",
            "15\n",
            "13\n",
            "15\n",
            "epoch 2 (227/272) | step 500 | avg_nll=25.20 avg_ppl=31.61 speed=4174.45 words/sec time_elapsed=40.44 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 500 | dev_ppl=28.394147872924805\n",
            "epoch 2 step 500: save currently the best model to 'model.pt'\n",
            "13\n",
            "17\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "14\n",
            "15\n",
            "epoch 2 (237/272) | step 510 | avg_nll=24.73 avg_ppl=30.30 speed=2491.88 words/sec time_elapsed=41.37 sec\n",
            "14\n",
            "12\n",
            "15\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "epoch 2 (247/272) | step 520 | avg_nll=24.82 avg_ppl=30.79 speed=4093.83 words/sec time_elapsed=41.94 sec\n",
            "14\n",
            "12\n",
            "14\n",
            "12\n",
            "16\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 2 (257/272) | step 530 | avg_nll=24.06 avg_ppl=28.48 speed=3802.03 words/sec time_elapsed=42.54 sec\n",
            "14\n",
            "12\n",
            "18\n",
            "15\n",
            "13\n",
            "13\n",
            "15\n",
            "13\n",
            "14\n",
            "15\n",
            "epoch 2 (267/272) | step 540 | avg_nll=25.04 avg_ppl=31.42 speed=3965.56 words/sec time_elapsed=43.13 sec\n",
            "13\n",
            "12\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "epoch 3 (5/272) | step 550 | avg_nll=23.91 avg_ppl=29.07 speed=3931.12 words/sec time_elapsed=43.71 sec\n",
            "12\n",
            "12\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "15\n",
            "16\n",
            "17\n",
            "epoch 3 (15/272) | step 560 | avg_nll=23.69 avg_ppl=26.73 speed=4072.61 words/sec time_elapsed=44.27 sec\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "13\n",
            "16\n",
            "14\n",
            "12\n",
            "13\n",
            "13\n",
            "epoch 3 (25/272) | step 570 | avg_nll=23.99 avg_ppl=27.30 speed=3985.98 words/sec time_elapsed=44.86 sec\n",
            "12\n",
            "15\n",
            "14\n",
            "15\n",
            "14\n",
            "14\n",
            "12\n",
            "15\n",
            "14\n",
            "13\n",
            "epoch 3 (35/272) | step 580 | avg_nll=24.67 avg_ppl=28.25 speed=3987.91 words/sec time_elapsed=45.45 sec\n",
            "13\n",
            "13\n",
            "15\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "13\n",
            "15\n",
            "epoch 3 (45/272) | step 590 | avg_nll=24.24 avg_ppl=28.01 speed=3822.61 words/sec time_elapsed=46.06 sec\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "15\n",
            "14\n",
            "12\n",
            "17\n",
            "13\n",
            "epoch 3 (55/272) | step 600 | avg_nll=23.58 avg_ppl=26.03 speed=3739.66 words/sec time_elapsed=46.68 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 600 | dev_ppl=24.40748405456543\n",
            "epoch 3 step 600: save currently the best model to 'model.pt'\n",
            "13\n",
            "12\n",
            "14\n",
            "18\n",
            "13\n",
            "13\n",
            "17\n",
            "13\n",
            "12\n",
            "12\n",
            "epoch 3 (65/272) | step 610 | avg_nll=23.79 avg_ppl=26.93 speed=2413.83 words/sec time_elapsed=47.64 sec\n",
            "14\n",
            "14\n",
            "15\n",
            "12\n",
            "14\n",
            "14\n",
            "14\n",
            "12\n",
            "12\n",
            "13\n",
            "epoch 3 (75/272) | step 620 | avg_nll=23.91 avg_ppl=26.69 speed=3919.73 words/sec time_elapsed=48.23 sec\n",
            "12\n",
            "12\n",
            "13\n",
            "12\n",
            "15\n",
            "13\n",
            "15\n",
            "13\n",
            "11\n",
            "13\n",
            "epoch 3 (85/272) | step 630 | avg_nll=22.34 avg_ppl=23.82 speed=2787.02 words/sec time_elapsed=49.04 sec\n",
            "14\n",
            "15\n",
            "13\n",
            "13\n",
            "12\n",
            "15\n",
            "14\n",
            "12\n",
            "13\n",
            "14\n",
            "epoch 3 (95/272) | step 640 | avg_nll=24.19 avg_ppl=26.67 speed=2838.57 words/sec time_elapsed=49.87 sec\n",
            "17\n",
            "12\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "12\n",
            "13\n",
            "epoch 3 (105/272) | step 650 | avg_nll=23.58 avg_ppl=25.43 speed=2698.58 words/sec time_elapsed=50.74 sec\n",
            "14\n",
            "15\n",
            "13\n",
            "15\n",
            "11\n",
            "16\n",
            "12\n",
            "12\n",
            "12\n",
            "14\n",
            "epoch 3 (115/272) | step 660 | avg_nll=22.62 avg_ppl=22.62 speed=2685.62 words/sec time_elapsed=51.60 sec\n",
            "12\n",
            "14\n",
            "13\n",
            "16\n",
            "14\n",
            "12\n",
            "15\n",
            "12\n",
            "14\n",
            "15\n",
            "epoch 3 (125/272) | step 670 | avg_nll=22.91 avg_ppl=24.31 speed=2696.63 words/sec time_elapsed=52.45 sec\n",
            "13\n",
            "12\n",
            "14\n",
            "13\n",
            "14\n",
            "15\n",
            "15\n",
            "12\n",
            "14\n",
            "13\n",
            "epoch 3 (135/272) | step 680 | avg_nll=24.02 avg_ppl=25.01 speed=3916.19 words/sec time_elapsed=53.06 sec\n",
            "13\n",
            "15\n",
            "15\n",
            "13\n",
            "14\n",
            "13\n",
            "17\n",
            "13\n",
            "12\n",
            "13\n",
            "epoch 3 (145/272) | step 690 | avg_nll=23.70 avg_ppl=25.26 speed=4171.18 words/sec time_elapsed=53.63 sec\n",
            "11\n",
            "13\n",
            "16\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "epoch 3 (155/272) | step 700 | avg_nll=22.11 avg_ppl=21.92 speed=3981.77 words/sec time_elapsed=54.20 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 700 | dev_ppl=22.29749870300293\n",
            "epoch 3 step 700: save currently the best model to 'model.pt'\n",
            "13\n",
            "12\n",
            "14\n",
            "14\n",
            "15\n",
            "12\n",
            "13\n",
            "13\n",
            "12\n",
            "14\n",
            "epoch 3 (165/272) | step 710 | avg_nll=22.57 avg_ppl=22.94 speed=2494.13 words/sec time_elapsed=55.13 sec\n",
            "14\n",
            "17\n",
            "14\n",
            "14\n",
            "14\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "12\n",
            "epoch 3 (175/272) | step 720 | avg_nll=24.41 avg_ppl=26.54 speed=4010.38 words/sec time_elapsed=55.72 sec\n",
            "12\n",
            "14\n",
            "14\n",
            "12\n",
            "13\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "11\n",
            "epoch 3 (185/272) | step 730 | avg_nll=21.59 avg_ppl=20.84 speed=4133.86 words/sec time_elapsed=56.27 sec\n",
            "15\n",
            "14\n",
            "15\n",
            "14\n",
            "14\n",
            "15\n",
            "14\n",
            "14\n",
            "13\n",
            "12\n",
            "epoch 3 (195/272) | step 740 | avg_nll=22.24 avg_ppl=21.25 speed=4099.13 words/sec time_elapsed=56.84 sec\n",
            "13\n",
            "12\n",
            "13\n",
            "13\n",
            "16\n",
            "13\n",
            "12\n",
            "13\n",
            "13\n",
            "11\n",
            "epoch 3 (205/272) | step 750 | avg_nll=22.50 avg_ppl=23.02 speed=3931.93 words/sec time_elapsed=57.42 sec\n",
            "17\n",
            "15\n",
            "14\n",
            "13\n",
            "16\n",
            "14\n",
            "12\n",
            "14\n",
            "15\n",
            "13\n",
            "epoch 3 (215/272) | step 760 | avg_nll=23.18 avg_ppl=24.33 speed=4051.10 words/sec time_elapsed=58.00 sec\n",
            "14\n",
            "12\n",
            "14\n",
            "14\n",
            "14\n",
            "11\n",
            "14\n",
            "15\n",
            "13\n",
            "12\n",
            "epoch 3 (225/272) | step 770 | avg_nll=21.37 avg_ppl=20.92 speed=3852.27 words/sec time_elapsed=58.58 sec\n",
            "13\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "12\n",
            "14\n",
            "13\n",
            "12\n",
            "14\n",
            "epoch 3 (235/272) | step 780 | avg_nll=23.11 avg_ppl=23.65 speed=4105.84 words/sec time_elapsed=59.15 sec\n",
            "16\n",
            "12\n",
            "13\n",
            "13\n",
            "14\n",
            "15\n",
            "14\n",
            "14\n",
            "15\n",
            "15\n",
            "epoch 3 (245/272) | step 790 | avg_nll=21.23 avg_ppl=19.43 speed=3963.01 words/sec time_elapsed=59.73 sec\n",
            "15\n",
            "13\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "epoch 3 (255/272) | step 800 | avg_nll=21.86 avg_ppl=21.21 speed=3920.87 words/sec time_elapsed=60.31 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 800 | dev_ppl=20.745824813842773\n",
            "epoch 3 step 800: save currently the best model to 'model.pt'\n",
            "12\n",
            "15\n",
            "13\n",
            "15\n",
            "14\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "15\n",
            "epoch 3 (265/272) | step 810 | avg_nll=23.05 avg_ppl=22.86 speed=2513.40 words/sec time_elapsed=61.25 sec\n",
            "15\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "13\n",
            "14\n",
            "epoch 4 (3/272) | step 820 | avg_nll=20.24 avg_ppl=17.57 speed=3890.17 words/sec time_elapsed=61.83 sec\n",
            "12\n",
            "12\n",
            "12\n",
            "12\n",
            "13\n",
            "15\n",
            "14\n",
            "15\n",
            "13\n",
            "12\n",
            "epoch 4 (13/272) | step 830 | avg_nll=21.05 avg_ppl=19.71 speed=3534.78 words/sec time_elapsed=62.47 sec\n",
            "13\n",
            "15\n",
            "15\n",
            "15\n",
            "13\n",
            "13\n",
            "16\n",
            "15\n",
            "15\n",
            "13\n",
            "epoch 4 (23/272) | step 840 | avg_nll=23.59 avg_ppl=23.82 speed=2728.84 words/sec time_elapsed=63.34 sec\n",
            "16\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "14\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "epoch 4 (33/272) | step 850 | avg_nll=22.04 avg_ppl=20.68 speed=2824.09 words/sec time_elapsed=64.17 sec\n",
            "12\n",
            "12\n",
            "12\n",
            "15\n",
            "13\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "epoch 4 (43/272) | step 860 | avg_nll=22.25 avg_ppl=20.49 speed=2678.29 words/sec time_elapsed=65.05 sec\n",
            "13\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "12\n",
            "15\n",
            "epoch 4 (53/272) | step 870 | avg_nll=21.85 avg_ppl=20.69 speed=2653.08 words/sec time_elapsed=65.92 sec\n",
            "12\n",
            "12\n",
            "15\n",
            "12\n",
            "12\n",
            "11\n",
            "13\n",
            "17\n",
            "14\n",
            "13\n",
            "epoch 4 (63/272) | step 880 | avg_nll=20.42 avg_ppl=17.35 speed=3473.16 words/sec time_elapsed=66.58 sec\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "17\n",
            "14\n",
            "13\n",
            "15\n",
            "12\n",
            "12\n",
            "epoch 4 (73/272) | step 890 | avg_nll=21.04 avg_ppl=18.58 speed=3944.96 words/sec time_elapsed=67.16 sec\n",
            "11\n",
            "15\n",
            "11\n",
            "15\n",
            "12\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "11\n",
            "epoch 4 (83/272) | step 900 | avg_nll=21.88 avg_ppl=19.52 speed=4035.67 words/sec time_elapsed=67.75 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 900 | dev_ppl=19.20347023010254\n",
            "epoch 4 step 900: save currently the best model to 'model.pt'\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "11\n",
            "16\n",
            "12\n",
            "13\n",
            "15\n",
            "13\n",
            "epoch 4 (93/272) | step 910 | avg_nll=19.90 avg_ppl=17.03 speed=2470.28 words/sec time_elapsed=68.66 sec\n",
            "15\n",
            "18\n",
            "14\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "epoch 4 (103/272) | step 920 | avg_nll=22.29 avg_ppl=20.82 speed=4218.60 words/sec time_elapsed=69.22 sec\n",
            "15\n",
            "13\n",
            "14\n",
            "11\n",
            "15\n",
            "13\n",
            "15\n",
            "13\n",
            "15\n",
            "14\n",
            "epoch 4 (113/272) | step 930 | avg_nll=22.11 avg_ppl=19.71 speed=4184.43 words/sec time_elapsed=69.78 sec\n",
            "15\n",
            "15\n",
            "14\n",
            "17\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "12\n",
            "16\n",
            "epoch 4 (123/272) | step 940 | avg_nll=21.60 avg_ppl=19.27 speed=4225.23 words/sec time_elapsed=70.34 sec\n",
            "17\n",
            "17\n",
            "13\n",
            "14\n",
            "13\n",
            "15\n",
            "14\n",
            "14\n",
            "13\n",
            "12\n",
            "epoch 4 (133/272) | step 950 | avg_nll=22.14 avg_ppl=20.39 speed=3866.50 words/sec time_elapsed=70.94 sec\n",
            "14\n",
            "14\n",
            "13\n",
            "13\n",
            "15\n",
            "13\n",
            "12\n",
            "14\n",
            "14\n",
            "13\n",
            "epoch 4 (143/272) | step 960 | avg_nll=20.71 avg_ppl=18.65 speed=3963.25 words/sec time_elapsed=71.52 sec\n",
            "13\n",
            "16\n",
            "14\n",
            "15\n",
            "12\n",
            "13\n",
            "16\n",
            "13\n",
            "15\n",
            "14\n",
            "epoch 4 (153/272) | step 970 | avg_nll=21.97 avg_ppl=20.24 speed=3918.96 words/sec time_elapsed=72.11 sec\n",
            "12\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "15\n",
            "12\n",
            "17\n",
            "15\n",
            "epoch 4 (163/272) | step 980 | avg_nll=20.85 avg_ppl=17.89 speed=3671.49 words/sec time_elapsed=72.74 sec\n",
            "14\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "epoch 4 (173/272) | step 990 | avg_nll=20.57 avg_ppl=17.63 speed=4012.85 words/sec time_elapsed=73.31 sec\n",
            "13\n",
            "12\n",
            "14\n",
            "12\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "15\n",
            "14\n",
            "epoch 4 (183/272) | step 1000 | avg_nll=22.10 avg_ppl=21.66 speed=3774.82 words/sec time_elapsed=73.92 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 1000 | dev_ppl=18.021595001220703\n",
            "epoch 4 step 1000: save currently the best model to 'model.pt'\n",
            "15\n",
            "16\n",
            "14\n",
            "15\n",
            "12\n",
            "15\n",
            "14\n",
            "14\n",
            "12\n",
            "14\n",
            "epoch 4 (193/272) | step 1010 | avg_nll=21.05 avg_ppl=18.97 speed=2515.10 words/sec time_elapsed=74.83 sec\n",
            "13\n",
            "15\n",
            "14\n",
            "12\n",
            "12\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "12\n",
            "epoch 4 (203/272) | step 1020 | avg_nll=20.66 avg_ppl=17.88 speed=4078.98 words/sec time_elapsed=75.40 sec\n",
            "14\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "12\n",
            "14\n",
            "12\n",
            "15\n",
            "12\n",
            "epoch 4 (213/272) | step 1030 | avg_nll=21.47 avg_ppl=18.85 speed=3947.80 words/sec time_elapsed=75.99 sec\n",
            "13\n",
            "11\n",
            "12\n",
            "13\n",
            "16\n",
            "16\n",
            "17\n",
            "14\n",
            "13\n",
            "14\n",
            "epoch 4 (223/272) | step 1040 | avg_nll=21.57 avg_ppl=19.06 speed=3046.17 words/sec time_elapsed=76.76 sec\n",
            "15\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "12\n",
            "epoch 4 (233/272) | step 1050 | avg_nll=21.20 avg_ppl=18.42 speed=2850.24 words/sec time_elapsed=77.58 sec\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "15\n",
            "13\n",
            "14\n",
            "13\n",
            "epoch 4 (243/272) | step 1060 | avg_nll=21.03 avg_ppl=18.33 speed=2705.20 words/sec time_elapsed=78.43 sec\n",
            "13\n",
            "13\n",
            "12\n",
            "14\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "16\n",
            "epoch 4 (253/272) | step 1070 | avg_nll=20.59 avg_ppl=17.03 speed=2656.10 words/sec time_elapsed=79.31 sec\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "13\n",
            "12\n",
            "12\n",
            "13\n",
            "epoch 4 (263/272) | step 1080 | avg_nll=20.43 avg_ppl=17.15 speed=3428.74 words/sec time_elapsed=79.98 sec\n",
            "13\n",
            "12\n",
            "16\n",
            "14\n",
            "15\n",
            "15\n",
            "13\n",
            "13\n",
            "14\n",
            "12\n",
            "epoch 5 (1/272) | step 1090 | avg_nll=20.41 avg_ppl=17.60 speed=3986.70 words/sec time_elapsed=80.55 sec\n",
            "18\n",
            "12\n",
            "16\n",
            "13\n",
            "13\n",
            "14\n",
            "12\n",
            "14\n",
            "12\n",
            "12\n",
            "epoch 5 (11/272) | step 1100 | avg_nll=20.69 avg_ppl=17.72 speed=3937.58 words/sec time_elapsed=81.14 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 1100 | dev_ppl=17.348297119140625\n",
            "epoch 5 step 1100: save currently the best model to 'model.pt'\n",
            "17\n",
            "15\n",
            "15\n",
            "16\n",
            "11\n",
            "13\n",
            "12\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 5 (21/272) | step 1110 | avg_nll=20.28 avg_ppl=16.67 speed=2455.66 words/sec time_elapsed=82.08 sec\n",
            "14\n",
            "14\n",
            "12\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "12\n",
            "epoch 5 (31/272) | step 1120 | avg_nll=20.95 avg_ppl=17.67 speed=4164.34 words/sec time_elapsed=82.64 sec\n",
            "14\n",
            "14\n",
            "15\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "12\n",
            "14\n",
            "13\n",
            "epoch 5 (41/272) | step 1130 | avg_nll=20.37 avg_ppl=16.55 speed=3875.98 words/sec time_elapsed=83.24 sec\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "15\n",
            "17\n",
            "13\n",
            "17\n",
            "13\n",
            "epoch 5 (51/272) | step 1140 | avg_nll=21.57 avg_ppl=19.24 speed=3696.28 words/sec time_elapsed=83.87 sec\n",
            "14\n",
            "12\n",
            "17\n",
            "14\n",
            "11\n",
            "13\n",
            "12\n",
            "16\n",
            "12\n",
            "13\n",
            "epoch 5 (61/272) | step 1150 | avg_nll=20.38 avg_ppl=16.41 speed=3933.05 words/sec time_elapsed=84.46 sec\n",
            "14\n",
            "13\n",
            "15\n",
            "15\n",
            "12\n",
            "14\n",
            "15\n",
            "13\n",
            "14\n",
            "15\n",
            "epoch 5 (71/272) | step 1160 | avg_nll=19.77 avg_ppl=15.70 speed=3622.73 words/sec time_elapsed=85.09 sec\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "12\n",
            "15\n",
            "epoch 5 (81/272) | step 1170 | avg_nll=21.45 avg_ppl=18.14 speed=4096.41 words/sec time_elapsed=85.67 sec\n",
            "13\n",
            "11\n",
            "12\n",
            "14\n",
            "15\n",
            "12\n",
            "14\n",
            "12\n",
            "16\n",
            "16\n",
            "epoch 5 (91/272) | step 1180 | avg_nll=19.19 avg_ppl=14.87 speed=3777.00 words/sec time_elapsed=86.27 sec\n",
            "14\n",
            "17\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "13\n",
            "15\n",
            "13\n",
            "12\n",
            "epoch 5 (101/272) | step 1190 | avg_nll=20.59 avg_ppl=16.38 speed=3955.41 words/sec time_elapsed=86.87 sec\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "epoch 5 (111/272) | step 1200 | avg_nll=20.20 avg_ppl=16.40 speed=4076.32 words/sec time_elapsed=87.44 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 1200 | dev_ppl=16.570541381835938\n",
            "epoch 5 step 1200: save currently the best model to 'model.pt'\n",
            "14\n",
            "13\n",
            "15\n",
            "15\n",
            "15\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "epoch 5 (121/272) | step 1210 | avg_nll=20.64 avg_ppl=17.18 speed=2490.75 words/sec time_elapsed=88.37 sec\n",
            "15\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "15\n",
            "12\n",
            "14\n",
            "epoch 5 (131/272) | step 1220 | avg_nll=19.25 avg_ppl=14.99 speed=4121.88 words/sec time_elapsed=88.92 sec\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "12\n",
            "15\n",
            "15\n",
            "13\n",
            "15\n",
            "13\n",
            "epoch 5 (141/272) | step 1230 | avg_nll=19.19 avg_ppl=14.56 speed=3865.07 words/sec time_elapsed=89.52 sec\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "13\n",
            "15\n",
            "13\n",
            "14\n",
            "epoch 5 (151/272) | step 1240 | avg_nll=19.76 avg_ppl=15.78 speed=2862.97 words/sec time_elapsed=90.32 sec\n",
            "13\n",
            "15\n",
            "14\n",
            "13\n",
            "15\n",
            "16\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 5 (161/272) | step 1250 | avg_nll=20.35 avg_ppl=16.77 speed=2919.81 words/sec time_elapsed=91.11 sec\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "11\n",
            "epoch 5 (171/272) | step 1260 | avg_nll=20.19 avg_ppl=15.86 speed=2734.04 words/sec time_elapsed=91.96 sec\n",
            "15\n",
            "11\n",
            "14\n",
            "14\n",
            "15\n",
            "14\n",
            "12\n",
            "12\n",
            "16\n",
            "12\n",
            "epoch 5 (181/272) | step 1270 | avg_nll=19.85 avg_ppl=15.87 speed=2527.72 words/sec time_elapsed=92.87 sec\n",
            "14\n",
            "11\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "16\n",
            "12\n",
            "11\n",
            "epoch 5 (191/272) | step 1280 | avg_nll=19.32 avg_ppl=15.28 speed=3546.75 words/sec time_elapsed=93.51 sec\n",
            "15\n",
            "13\n",
            "15\n",
            "13\n",
            "15\n",
            "15\n",
            "12\n",
            "13\n",
            "14\n",
            "14\n",
            "epoch 5 (201/272) | step 1290 | avg_nll=20.37 avg_ppl=16.54 speed=4223.80 words/sec time_elapsed=94.06 sec\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "15\n",
            "12\n",
            "13\n",
            "14\n",
            "epoch 5 (211/272) | step 1300 | avg_nll=19.93 avg_ppl=15.26 speed=3846.20 words/sec time_elapsed=94.67 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 1300 | dev_ppl=15.855949401855469\n",
            "epoch 5 step 1300: save currently the best model to 'model.pt'\n",
            "12\n",
            "15\n",
            "14\n",
            "14\n",
            "13\n",
            "15\n",
            "14\n",
            "15\n",
            "14\n",
            "13\n",
            "epoch 5 (221/272) | step 1310 | avg_nll=21.16 avg_ppl=17.98 speed=2557.95 words/sec time_elapsed=95.59 sec\n",
            "13\n",
            "14\n",
            "13\n",
            "17\n",
            "14\n",
            "12\n",
            "13\n",
            "16\n",
            "12\n",
            "13\n",
            "epoch 5 (231/272) | step 1320 | avg_nll=19.58 avg_ppl=15.16 speed=4304.60 words/sec time_elapsed=96.12 sec\n",
            "14\n",
            "12\n",
            "17\n",
            "13\n",
            "14\n",
            "16\n",
            "13\n",
            "14\n",
            "15\n",
            "15\n",
            "epoch 5 (241/272) | step 1330 | avg_nll=19.52 avg_ppl=14.90 speed=4000.14 words/sec time_elapsed=96.70 sec\n",
            "12\n",
            "13\n",
            "14\n",
            "12\n",
            "14\n",
            "13\n",
            "13\n",
            "15\n",
            "12\n",
            "12\n",
            "epoch 5 (251/272) | step 1340 | avg_nll=21.20 avg_ppl=17.09 speed=4068.61 words/sec time_elapsed=97.29 sec\n",
            "12\n",
            "13\n",
            "14\n",
            "14\n",
            "16\n",
            "12\n",
            "12\n",
            "15\n",
            "13\n",
            "14\n",
            "epoch 5 (261/272) | step 1350 | avg_nll=19.88 avg_ppl=15.15 speed=3849.37 words/sec time_elapsed=97.90 sec\n",
            "14\n",
            "15\n",
            "15\n",
            "13\n",
            "12\n",
            "13\n",
            "15\n",
            "12\n",
            "13\n",
            "12\n",
            "epoch 5 (271/272) | step 1360 | avg_nll=18.67 avg_ppl=13.93 speed=3881.49 words/sec time_elapsed=98.48 sec\n",
            "13\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "epoch 6 (9/272) | step 1370 | avg_nll=19.29 avg_ppl=14.37 speed=4008.99 words/sec time_elapsed=99.06 sec\n",
            "12\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "13\n",
            "15\n",
            "13\n",
            "14\n",
            "13\n",
            "epoch 6 (19/272) | step 1380 | avg_nll=18.90 avg_ppl=14.18 speed=4087.22 words/sec time_elapsed=99.62 sec\n",
            "13\n",
            "13\n",
            "15\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "15\n",
            "13\n",
            "12\n",
            "epoch 6 (29/272) | step 1390 | avg_nll=19.86 avg_ppl=15.53 speed=4045.76 words/sec time_elapsed=100.19 sec\n",
            "15\n",
            "12\n",
            "14\n",
            "13\n",
            "16\n",
            "15\n",
            "14\n",
            "14\n",
            "17\n",
            "14\n",
            "epoch 6 (39/272) | step 1400 | avg_nll=19.46 avg_ppl=14.82 speed=4017.50 words/sec time_elapsed=100.76 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 1400 | dev_ppl=15.190228462219238\n",
            "epoch 6 step 1400: save currently the best model to 'model.pt'\n",
            "12\n",
            "17\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "13\n",
            "15\n",
            "14\n",
            "14\n",
            "epoch 6 (49/272) | step 1410 | avg_nll=20.30 avg_ppl=15.61 speed=2519.46 words/sec time_elapsed=101.70 sec\n",
            "16\n",
            "16\n",
            "12\n",
            "14\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "15\n",
            "14\n",
            "epoch 6 (59/272) | step 1420 | avg_nll=18.78 avg_ppl=13.76 speed=3714.96 words/sec time_elapsed=102.32 sec\n",
            "13\n",
            "12\n",
            "12\n",
            "15\n",
            "14\n",
            "12\n",
            "12\n",
            "14\n",
            "15\n",
            "13\n",
            "epoch 6 (69/272) | step 1430 | avg_nll=18.64 avg_ppl=13.25 speed=4005.21 words/sec time_elapsed=102.90 sec\n",
            "13\n",
            "12\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "16\n",
            "15\n",
            "epoch 6 (79/272) | step 1440 | avg_nll=18.54 avg_ppl=12.99 speed=2855.34 words/sec time_elapsed=103.71 sec\n",
            "14\n",
            "15\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "15\n",
            "15\n",
            "14\n",
            "13\n",
            "epoch 6 (89/272) | step 1450 | avg_nll=20.48 avg_ppl=16.84 speed=2848.53 words/sec time_elapsed=104.52 sec\n",
            "13\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "14\n",
            "14\n",
            "13\n",
            "16\n",
            "11\n",
            "epoch 6 (99/272) | step 1460 | avg_nll=18.59 avg_ppl=13.46 speed=2559.35 words/sec time_elapsed=105.42 sec\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "11\n",
            "14\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "epoch 6 (109/272) | step 1470 | avg_nll=18.84 avg_ppl=13.09 speed=2628.11 words/sec time_elapsed=106.31 sec\n",
            "12\n",
            "16\n",
            "13\n",
            "16\n",
            "12\n",
            "15\n",
            "14\n",
            "12\n",
            "13\n",
            "12\n",
            "epoch 6 (119/272) | step 1480 | avg_nll=19.77 avg_ppl=14.56 speed=3477.68 words/sec time_elapsed=106.99 sec\n",
            "14\n",
            "14\n",
            "13\n",
            "12\n",
            "14\n",
            "12\n",
            "14\n",
            "12\n",
            "13\n",
            "12\n",
            "epoch 6 (129/272) | step 1490 | avg_nll=20.43 avg_ppl=16.08 speed=4015.79 words/sec time_elapsed=107.58 sec\n",
            "14\n",
            "15\n",
            "13\n",
            "15\n",
            "15\n",
            "15\n",
            "12\n",
            "13\n",
            "14\n",
            "13\n",
            "epoch 6 (139/272) | step 1500 | avg_nll=19.67 avg_ppl=14.62 speed=4112.55 words/sec time_elapsed=108.15 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 1500 | dev_ppl=14.589966773986816\n",
            "epoch 6 step 1500: save currently the best model to 'model.pt'\n",
            "17\n",
            "14\n",
            "13\n",
            "14\n",
            "12\n",
            "17\n",
            "13\n",
            "12\n",
            "14\n",
            "13\n",
            "epoch 6 (149/272) | step 1510 | avg_nll=20.24 avg_ppl=15.13 speed=2578.06 words/sec time_elapsed=109.07 sec\n",
            "14\n",
            "15\n",
            "13\n",
            "13\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "17\n",
            "13\n",
            "epoch 6 (159/272) | step 1520 | avg_nll=19.42 avg_ppl=15.15 speed=2027.02 words/sec time_elapsed=110.20 sec\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "13\n",
            "epoch 6 (169/272) | step 1530 | avg_nll=19.98 avg_ppl=14.98 speed=2009.24 words/sec time_elapsed=111.38 sec\n",
            "13\n",
            "17\n",
            "14\n",
            "14\n",
            "14\n",
            "16\n",
            "12\n",
            "14\n",
            "15\n",
            "14\n",
            "epoch 6 (179/272) | step 1540 | avg_nll=18.57 avg_ppl=13.59 speed=1989.10 words/sec time_elapsed=112.52 sec\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "12\n",
            "epoch 6 (189/272) | step 1550 | avg_nll=19.15 avg_ppl=13.79 speed=4316.43 words/sec time_elapsed=113.06 sec\n",
            "14\n",
            "14\n",
            "15\n",
            "15\n",
            "13\n",
            "12\n",
            "15\n",
            "12\n",
            "14\n",
            "15\n",
            "epoch 6 (199/272) | step 1560 | avg_nll=18.13 avg_ppl=12.92 speed=3648.77 words/sec time_elapsed=113.68 sec\n",
            "18\n",
            "14\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "15\n",
            "13\n",
            "12\n",
            "13\n",
            "epoch 6 (209/272) | step 1570 | avg_nll=19.03 avg_ppl=13.85 speed=3835.32 words/sec time_elapsed=114.29 sec\n",
            "12\n",
            "12\n",
            "16\n",
            "14\n",
            "14\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "13\n",
            "epoch 6 (219/272) | step 1580 | avg_nll=19.20 avg_ppl=13.67 speed=4062.17 words/sec time_elapsed=114.87 sec\n",
            "14\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "15\n",
            "14\n",
            "15\n",
            "12\n",
            "14\n",
            "epoch 6 (229/272) | step 1590 | avg_nll=17.95 avg_ppl=12.64 speed=4002.76 words/sec time_elapsed=115.43 sec\n",
            "12\n",
            "13\n",
            "14\n",
            "12\n",
            "14\n",
            "14\n",
            "14\n",
            "12\n",
            "14\n",
            "12\n",
            "epoch 6 (239/272) | step 1600 | avg_nll=18.90 avg_ppl=13.49 speed=4201.03 words/sec time_elapsed=115.99 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 1600 | dev_ppl=14.344023704528809\n",
            "epoch 6 step 1600: save currently the best model to 'model.pt'\n",
            "12\n",
            "13\n",
            "13\n",
            "14\n",
            "15\n",
            "12\n",
            "12\n",
            "13\n",
            "13\n",
            "14\n",
            "epoch 6 (249/272) | step 1610 | avg_nll=18.27 avg_ppl=12.85 speed=2088.36 words/sec time_elapsed=117.08 sec\n",
            "14\n",
            "12\n",
            "12\n",
            "17\n",
            "14\n",
            "15\n",
            "14\n",
            "15\n",
            "14\n",
            "14\n",
            "epoch 6 (259/272) | step 1620 | avg_nll=18.38 avg_ppl=12.81 speed=2689.04 words/sec time_elapsed=117.94 sec\n",
            "13\n",
            "12\n",
            "13\n",
            "12\n",
            "12\n",
            "13\n",
            "16\n",
            "11\n",
            "15\n",
            "13\n",
            "epoch 6 (269/272) | step 1630 | avg_nll=18.90 avg_ppl=13.76 speed=2852.26 words/sec time_elapsed=118.75 sec\n",
            "15\n",
            "12\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "16\n",
            "14\n",
            "15\n",
            "14\n",
            "epoch 7 (7/272) | step 1640 | avg_nll=18.22 avg_ppl=13.13 speed=2656.41 words/sec time_elapsed=119.60 sec\n",
            "13\n",
            "13\n",
            "17\n",
            "15\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "15\n",
            "18\n",
            "epoch 7 (17/272) | step 1650 | avg_nll=18.94 avg_ppl=13.31 speed=3136.88 words/sec time_elapsed=120.35 sec\n",
            "13\n",
            "12\n",
            "14\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "epoch 7 (27/272) | step 1660 | avg_nll=16.96 avg_ppl=11.01 speed=3951.47 words/sec time_elapsed=120.92 sec\n",
            "13\n",
            "14\n",
            "12\n",
            "14\n",
            "13\n",
            "17\n",
            "12\n",
            "13\n",
            "12\n",
            "15\n",
            "epoch 7 (37/272) | step 1670 | avg_nll=18.10 avg_ppl=12.32 speed=3958.53 words/sec time_elapsed=121.51 sec\n",
            "15\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "16\n",
            "15\n",
            "14\n",
            "12\n",
            "epoch 7 (47/272) | step 1680 | avg_nll=18.21 avg_ppl=12.54 speed=3914.97 words/sec time_elapsed=122.09 sec\n",
            "13\n",
            "13\n",
            "17\n",
            "13\n",
            "14\n",
            "16\n",
            "14\n",
            "14\n",
            "12\n",
            "17\n",
            "epoch 7 (57/272) | step 1690 | avg_nll=19.21 avg_ppl=14.03 speed=3772.16 words/sec time_elapsed=122.71 sec\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "12\n",
            "16\n",
            "13\n",
            "11\n",
            "12\n",
            "14\n",
            "epoch 7 (67/272) | step 1700 | avg_nll=18.48 avg_ppl=13.15 speed=4161.63 words/sec time_elapsed=123.26 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 1700 | dev_ppl=13.968740463256836\n",
            "epoch 7 step 1700: save currently the best model to 'model.pt'\n",
            "13\n",
            "14\n",
            "12\n",
            "15\n",
            "16\n",
            "13\n",
            "15\n",
            "15\n",
            "15\n",
            "13\n",
            "epoch 7 (77/272) | step 1710 | avg_nll=17.96 avg_ppl=12.60 speed=2458.46 words/sec time_elapsed=124.19 sec\n",
            "12\n",
            "13\n",
            "13\n",
            "11\n",
            "12\n",
            "13\n",
            "12\n",
            "15\n",
            "16\n",
            "15\n",
            "epoch 7 (87/272) | step 1720 | avg_nll=18.20 avg_ppl=12.35 speed=3883.88 words/sec time_elapsed=124.78 sec\n",
            "13\n",
            "13\n",
            "12\n",
            "12\n",
            "13\n",
            "14\n",
            "13\n",
            "11\n",
            "12\n",
            "13\n",
            "epoch 7 (97/272) | step 1730 | avg_nll=17.46 avg_ppl=11.49 speed=3868.83 words/sec time_elapsed=125.37 sec\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "11\n",
            "14\n",
            "15\n",
            "14\n",
            "15\n",
            "14\n",
            "epoch 7 (107/272) | step 1740 | avg_nll=18.84 avg_ppl=13.48 speed=4093.58 words/sec time_elapsed=125.94 sec\n",
            "15\n",
            "14\n",
            "12\n",
            "12\n",
            "15\n",
            "15\n",
            "13\n",
            "16\n",
            "13\n",
            "15\n",
            "epoch 7 (117/272) | step 1750 | avg_nll=19.28 avg_ppl=13.96 speed=4184.00 words/sec time_elapsed=126.50 sec\n",
            "13\n",
            "15\n",
            "14\n",
            "16\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "epoch 7 (127/272) | step 1760 | avg_nll=18.51 avg_ppl=12.77 speed=4023.61 words/sec time_elapsed=127.08 sec\n",
            "13\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "12\n",
            "17\n",
            "13\n",
            "15\n",
            "12\n",
            "epoch 7 (137/272) | step 1770 | avg_nll=16.68 avg_ppl=10.52 speed=3979.85 words/sec time_elapsed=127.65 sec\n",
            "15\n",
            "13\n",
            "14\n",
            "12\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "epoch 7 (147/272) | step 1780 | avg_nll=18.34 avg_ppl=12.38 speed=3924.14 words/sec time_elapsed=128.24 sec\n",
            "14\n",
            "13\n",
            "13\n",
            "17\n",
            "14\n",
            "13\n",
            "12\n",
            "15\n",
            "13\n",
            "13\n",
            "epoch 7 (157/272) | step 1790 | avg_nll=17.71 avg_ppl=11.74 speed=3846.59 words/sec time_elapsed=128.84 sec\n",
            "15\n",
            "14\n",
            "12\n",
            "13\n",
            "15\n",
            "12\n",
            "14\n",
            "13\n",
            "15\n",
            "12\n",
            "epoch 7 (167/272) | step 1800 | avg_nll=18.83 avg_ppl=12.81 speed=3787.89 words/sec time_elapsed=129.47 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 1800 | dev_ppl=13.550040245056152\n",
            "epoch 7 step 1800: save currently the best model to 'model.pt'\n",
            "14\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "12\n",
            "15\n",
            "15\n",
            "12\n",
            "15\n",
            "epoch 7 (177/272) | step 1810 | avg_nll=18.53 avg_ppl=12.68 speed=2266.59 words/sec time_elapsed=130.50 sec\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "12\n",
            "15\n",
            "15\n",
            "13\n",
            "epoch 7 (187/272) | step 1820 | avg_nll=18.42 avg_ppl=12.56 speed=2793.67 words/sec time_elapsed=131.33 sec\n",
            "14\n",
            "14\n",
            "12\n",
            "16\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 7 (197/272) | step 1830 | avg_nll=18.70 avg_ppl=13.13 speed=2701.51 words/sec time_elapsed=132.19 sec\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "14\n",
            "13\n",
            "14\n",
            "epoch 7 (207/272) | step 1840 | avg_nll=18.88 avg_ppl=13.44 speed=2636.65 words/sec time_elapsed=133.07 sec\n",
            "12\n",
            "12\n",
            "14\n",
            "13\n",
            "14\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "12\n",
            "epoch 7 (217/272) | step 1850 | avg_nll=18.27 avg_ppl=12.17 speed=2766.42 words/sec time_elapsed=133.92 sec\n",
            "14\n",
            "14\n",
            "14\n",
            "12\n",
            "12\n",
            "14\n",
            "15\n",
            "14\n",
            "14\n",
            "13\n",
            "epoch 7 (227/272) | step 1860 | avg_nll=19.37 avg_ppl=13.93 speed=3878.42 words/sec time_elapsed=134.53 sec\n",
            "14\n",
            "14\n",
            "14\n",
            "17\n",
            "12\n",
            "14\n",
            "13\n",
            "14\n",
            "15\n",
            "12\n",
            "epoch 7 (237/272) | step 1870 | avg_nll=19.28 avg_ppl=13.68 speed=3910.56 words/sec time_elapsed=135.13 sec\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "11\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 7 (247/272) | step 1880 | avg_nll=17.98 avg_ppl=12.15 speed=3962.10 words/sec time_elapsed=135.71 sec\n",
            "14\n",
            "12\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "13\n",
            "13\n",
            "12\n",
            "15\n",
            "epoch 7 (257/272) | step 1890 | avg_nll=17.78 avg_ppl=11.24 speed=3729.61 words/sec time_elapsed=136.34 sec\n",
            "13\n",
            "11\n",
            "15\n",
            "14\n",
            "13\n",
            "12\n",
            "14\n",
            "14\n",
            "12\n",
            "14\n",
            "epoch 7 (267/272) | step 1900 | avg_nll=17.21 avg_ppl=11.02 speed=3777.95 words/sec time_elapsed=136.95 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 1900 | dev_ppl=12.880881309509277\n",
            "epoch 7 step 1900: save currently the best model to 'model.pt'\n",
            "15\n",
            "14\n",
            "15\n",
            "13\n",
            "15\n",
            "14\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "epoch 8 (5/272) | step 1910 | avg_nll=18.11 avg_ppl=12.75 speed=2434.90 words/sec time_elapsed=137.88 sec\n",
            "12\n",
            "14\n",
            "12\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "epoch 8 (15/272) | step 1920 | avg_nll=17.03 avg_ppl=10.92 speed=3764.34 words/sec time_elapsed=138.49 sec\n",
            "14\n",
            "15\n",
            "15\n",
            "13\n",
            "12\n",
            "14\n",
            "15\n",
            "12\n",
            "15\n",
            "14\n",
            "epoch 8 (25/272) | step 1930 | avg_nll=18.47 avg_ppl=12.53 speed=3848.58 words/sec time_elapsed=139.10 sec\n",
            "16\n",
            "16\n",
            "15\n",
            "13\n",
            "15\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 8 (35/272) | step 1940 | avg_nll=18.43 avg_ppl=12.05 speed=3765.50 words/sec time_elapsed=139.73 sec\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "14\n",
            "15\n",
            "13\n",
            "12\n",
            "16\n",
            "13\n",
            "epoch 8 (45/272) | step 1950 | avg_nll=17.19 avg_ppl=11.31 speed=3880.16 words/sec time_elapsed=140.31 sec\n",
            "12\n",
            "12\n",
            "14\n",
            "12\n",
            "15\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "epoch 8 (55/272) | step 1960 | avg_nll=16.70 avg_ppl=10.43 speed=3877.53 words/sec time_elapsed=140.90 sec\n",
            "12\n",
            "15\n",
            "13\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "11\n",
            "13\n",
            "epoch 8 (65/272) | step 1970 | avg_nll=17.44 avg_ppl=11.19 speed=3752.46 words/sec time_elapsed=141.52 sec\n",
            "12\n",
            "17\n",
            "16\n",
            "14\n",
            "11\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "15\n",
            "epoch 8 (75/272) | step 1980 | avg_nll=17.09 avg_ppl=10.80 speed=3885.57 words/sec time_elapsed=142.11 sec\n",
            "14\n",
            "11\n",
            "15\n",
            "15\n",
            "12\n",
            "14\n",
            "18\n",
            "13\n",
            "14\n",
            "12\n",
            "epoch 8 (85/272) | step 1990 | avg_nll=17.93 avg_ppl=11.62 speed=3868.00 words/sec time_elapsed=142.71 sec\n",
            "15\n",
            "15\n",
            "13\n",
            "13\n",
            "14\n",
            "12\n",
            "17\n",
            "13\n",
            "13\n",
            "11\n",
            "epoch 8 (95/272) | step 2000 | avg_nll=17.71 avg_ppl=11.23 speed=4044.05 words/sec time_elapsed=143.29 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 2000 | dev_ppl=12.51210880279541\n",
            "epoch 8 step 2000: save currently the best model to 'model.pt'\n",
            "14\n",
            "12\n",
            "14\n",
            "15\n",
            "13\n",
            "14\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "epoch 8 (105/272) | step 2010 | avg_nll=17.29 avg_ppl=10.79 speed=2078.74 words/sec time_elapsed=144.41 sec\n",
            "13\n",
            "14\n",
            "17\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "epoch 8 (115/272) | step 2020 | avg_nll=17.42 avg_ppl=10.93 speed=2650.14 words/sec time_elapsed=145.29 sec\n",
            "14\n",
            "13\n",
            "14\n",
            "12\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "11\n",
            "13\n",
            "epoch 8 (125/272) | step 2030 | avg_nll=18.50 avg_ppl=12.45 speed=2688.88 words/sec time_elapsed=146.17 sec\n",
            "13\n",
            "12\n",
            "15\n",
            "13\n",
            "14\n",
            "13\n",
            "12\n",
            "12\n",
            "15\n",
            "16\n",
            "epoch 8 (135/272) | step 2040 | avg_nll=16.10 avg_ppl=9.35 speed=2672.45 words/sec time_elapsed=147.03 sec\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "15\n",
            "13\n",
            "epoch 8 (145/272) | step 2050 | avg_nll=17.35 avg_ppl=10.81 speed=2718.12 words/sec time_elapsed=147.89 sec\n",
            "12\n",
            "14\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "13\n",
            "15\n",
            "14\n",
            "13\n",
            "epoch 8 (155/272) | step 2060 | avg_nll=16.48 avg_ppl=10.05 speed=3616.62 words/sec time_elapsed=148.52 sec\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "12\n",
            "14\n",
            "13\n",
            "12\n",
            "14\n",
            "epoch 8 (165/272) | step 2070 | avg_nll=18.21 avg_ppl=12.06 speed=3735.11 words/sec time_elapsed=149.15 sec\n",
            "16\n",
            "14\n",
            "12\n",
            "15\n",
            "14\n",
            "14\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "epoch 8 (175/272) | step 2080 | avg_nll=17.29 avg_ppl=11.05 speed=3782.03 words/sec time_elapsed=149.76 sec\n",
            "13\n",
            "14\n",
            "15\n",
            "15\n",
            "13\n",
            "17\n",
            "14\n",
            "16\n",
            "13\n",
            "12\n",
            "epoch 8 (185/272) | step 2090 | avg_nll=17.43 avg_ppl=11.06 speed=3888.33 words/sec time_elapsed=150.35 sec\n",
            "14\n",
            "17\n",
            "12\n",
            "16\n",
            "15\n",
            "16\n",
            "12\n",
            "14\n",
            "12\n",
            "14\n",
            "epoch 8 (195/272) | step 2100 | avg_nll=18.23 avg_ppl=12.18 speed=3994.12 words/sec time_elapsed=150.94 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 2100 | dev_ppl=12.336102485656738\n",
            "epoch 8 step 2100: save currently the best model to 'model.pt'\n",
            "12\n",
            "13\n",
            "13\n",
            "13\n",
            "15\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "11\n",
            "epoch 8 (205/272) | step 2110 | avg_nll=16.99 avg_ppl=10.57 speed=2498.55 words/sec time_elapsed=151.86 sec\n",
            "15\n",
            "16\n",
            "12\n",
            "14\n",
            "11\n",
            "13\n",
            "13\n",
            "15\n",
            "14\n",
            "13\n",
            "epoch 8 (215/272) | step 2120 | avg_nll=17.74 avg_ppl=11.65 speed=4305.44 words/sec time_elapsed=152.40 sec\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "14\n",
            "14\n",
            "16\n",
            "epoch 8 (225/272) | step 2130 | avg_nll=17.68 avg_ppl=11.56 speed=4078.62 words/sec time_elapsed=152.97 sec\n",
            "13\n",
            "15\n",
            "14\n",
            "17\n",
            "12\n",
            "12\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 8 (235/272) | step 2140 | avg_nll=17.35 avg_ppl=10.89 speed=3977.78 words/sec time_elapsed=153.55 sec\n",
            "13\n",
            "15\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "15\n",
            "13\n",
            "epoch 8 (245/272) | step 2150 | avg_nll=18.42 avg_ppl=12.25 speed=3730.53 words/sec time_elapsed=154.18 sec\n",
            "13\n",
            "13\n",
            "15\n",
            "14\n",
            "15\n",
            "13\n",
            "13\n",
            "15\n",
            "13\n",
            "12\n",
            "epoch 8 (255/272) | step 2160 | avg_nll=17.72 avg_ppl=11.73 speed=3664.93 words/sec time_elapsed=154.81 sec\n",
            "14\n",
            "12\n",
            "13\n",
            "13\n",
            "14\n",
            "11\n",
            "14\n",
            "17\n",
            "12\n",
            "15\n",
            "epoch 8 (265/272) | step 2170 | avg_nll=16.79 avg_ppl=10.04 speed=4010.15 words/sec time_elapsed=155.39 sec\n",
            "12\n",
            "14\n",
            "13\n",
            "13\n",
            "12\n",
            "14\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "epoch 9 (3/272) | step 2180 | avg_nll=16.86 avg_ppl=10.65 speed=3960.95 words/sec time_elapsed=155.97 sec\n",
            "15\n",
            "12\n",
            "15\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "15\n",
            "epoch 9 (13/272) | step 2190 | avg_nll=17.01 avg_ppl=10.23 speed=4111.48 words/sec time_elapsed=156.54 sec\n",
            "12\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "13\n",
            "12\n",
            "epoch 9 (23/272) | step 2200 | avg_nll=16.35 avg_ppl=9.32 speed=3979.52 words/sec time_elapsed=157.12 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 2200 | dev_ppl=12.676145553588867\n",
            "13\n",
            "14\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "11\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 9 (33/272) | step 2210 | avg_nll=15.50 avg_ppl=9.00 speed=2171.25 words/sec time_elapsed=158.16 sec\n",
            "15\n",
            "14\n",
            "15\n",
            "11\n",
            "15\n",
            "13\n",
            "15\n",
            "15\n",
            "13\n",
            "15\n",
            "epoch 9 (43/272) | step 2220 | avg_nll=16.94 avg_ppl=10.28 speed=2633.18 words/sec time_elapsed=159.05 sec\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "12\n",
            "15\n",
            "15\n",
            "13\n",
            "epoch 9 (53/272) | step 2230 | avg_nll=17.01 avg_ppl=10.70 speed=2771.49 words/sec time_elapsed=159.88 sec\n",
            "14\n",
            "14\n",
            "13\n",
            "16\n",
            "12\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 9 (63/272) | step 2240 | avg_nll=16.41 avg_ppl=9.52 speed=2650.57 words/sec time_elapsed=160.76 sec\n",
            "16\n",
            "13\n",
            "14\n",
            "15\n",
            "15\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 9 (73/272) | step 2250 | avg_nll=17.14 avg_ppl=10.47 speed=2619.14 words/sec time_elapsed=161.65 sec\n",
            "15\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "14\n",
            "11\n",
            "13\n",
            "epoch 9 (83/272) | step 2260 | avg_nll=16.74 avg_ppl=10.16 speed=3878.32 words/sec time_elapsed=162.24 sec\n",
            "17\n",
            "17\n",
            "13\n",
            "12\n",
            "13\n",
            "15\n",
            "15\n",
            "13\n",
            "13\n",
            "12\n",
            "epoch 9 (93/272) | step 2270 | avg_nll=16.31 avg_ppl=9.68 speed=3957.00 words/sec time_elapsed=162.83 sec\n",
            "12\n",
            "15\n",
            "15\n",
            "14\n",
            "13\n",
            "13\n",
            "15\n",
            "12\n",
            "14\n",
            "12\n",
            "epoch 9 (103/272) | step 2280 | avg_nll=16.21 avg_ppl=9.67 speed=3910.12 words/sec time_elapsed=163.41 sec\n",
            "15\n",
            "15\n",
            "12\n",
            "16\n",
            "14\n",
            "13\n",
            "13\n",
            "17\n",
            "14\n",
            "12\n",
            "epoch 9 (113/272) | step 2290 | avg_nll=16.62 avg_ppl=10.02 speed=3959.59 words/sec time_elapsed=163.99 sec\n",
            "12\n",
            "15\n",
            "13\n",
            "13\n",
            "13\n",
            "15\n",
            "13\n",
            "14\n",
            "14\n",
            "17\n",
            "epoch 9 (123/272) | step 2300 | avg_nll=16.38 avg_ppl=9.82 speed=3897.67 words/sec time_elapsed=164.58 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 2300 | dev_ppl=11.847198486328125\n",
            "epoch 9 step 2300: save currently the best model to 'model.pt'\n",
            "13\n",
            "17\n",
            "13\n",
            "15\n",
            "15\n",
            "12\n",
            "14\n",
            "13\n",
            "14\n",
            "12\n",
            "epoch 9 (133/272) | step 2310 | avg_nll=17.44 avg_ppl=10.62 speed=2578.11 words/sec time_elapsed=165.50 sec\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "13\n",
            "12\n",
            "16\n",
            "epoch 9 (143/272) | step 2320 | avg_nll=16.57 avg_ppl=9.91 speed=4043.60 words/sec time_elapsed=166.07 sec\n",
            "12\n",
            "14\n",
            "14\n",
            "12\n",
            "14\n",
            "15\n",
            "15\n",
            "15\n",
            "14\n",
            "15\n",
            "epoch 9 (153/272) | step 2330 | avg_nll=17.18 avg_ppl=10.48 speed=3702.09 words/sec time_elapsed=166.70 sec\n",
            "14\n",
            "15\n",
            "12\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "14\n",
            "16\n",
            "epoch 9 (163/272) | step 2340 | avg_nll=16.68 avg_ppl=9.82 speed=4020.74 words/sec time_elapsed=167.28 sec\n",
            "14\n",
            "16\n",
            "14\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "16\n",
            "15\n",
            "epoch 9 (173/272) | step 2350 | avg_nll=17.36 avg_ppl=10.40 speed=3797.79 words/sec time_elapsed=167.91 sec\n",
            "13\n",
            "10\n",
            "13\n",
            "14\n",
            "15\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "15\n",
            "epoch 9 (183/272) | step 2360 | avg_nll=16.98 avg_ppl=10.28 speed=3832.72 words/sec time_elapsed=168.52 sec\n",
            "13\n",
            "12\n",
            "15\n",
            "14\n",
            "14\n",
            "13\n",
            "12\n",
            "12\n",
            "13\n",
            "14\n",
            "epoch 9 (193/272) | step 2370 | avg_nll=17.42 avg_ppl=11.03 speed=4107.99 words/sec time_elapsed=169.08 sec\n",
            "11\n",
            "17\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "13\n",
            "17\n",
            "epoch 9 (203/272) | step 2380 | avg_nll=17.95 avg_ppl=11.44 speed=3869.73 words/sec time_elapsed=169.69 sec\n",
            "13\n",
            "12\n",
            "13\n",
            "12\n",
            "14\n",
            "14\n",
            "15\n",
            "14\n",
            "12\n",
            "13\n",
            "epoch 9 (213/272) | step 2390 | avg_nll=16.33 avg_ppl=10.07 speed=3870.16 words/sec time_elapsed=170.28 sec\n",
            "14\n",
            "13\n",
            "15\n",
            "16\n",
            "15\n",
            "16\n",
            "18\n",
            "14\n",
            "13\n",
            "14\n",
            "epoch 9 (223/272) | step 2400 | avg_nll=17.22 avg_ppl=10.52 speed=3949.36 words/sec time_elapsed=170.87 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 2400 | dev_ppl=11.565973281860352\n",
            "epoch 9 step 2400: save currently the best model to 'model.pt'\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "12\n",
            "14\n",
            "13\n",
            "epoch 9 (233/272) | step 2410 | avg_nll=16.26 avg_ppl=9.51 speed=2231.52 words/sec time_elapsed=171.90 sec\n",
            "12\n",
            "13\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "13\n",
            "11\n",
            "14\n",
            "15\n",
            "epoch 9 (243/272) | step 2420 | avg_nll=15.86 avg_ppl=9.30 speed=2723.89 words/sec time_elapsed=172.74 sec\n",
            "13\n",
            "13\n",
            "15\n",
            "12\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "11\n",
            "13\n",
            "epoch 9 (253/272) | step 2430 | avg_nll=17.05 avg_ppl=10.47 speed=2789.54 words/sec time_elapsed=173.57 sec\n",
            "11\n",
            "14\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "12\n",
            "15\n",
            "epoch 9 (263/272) | step 2440 | avg_nll=16.61 avg_ppl=10.11 speed=2721.40 words/sec time_elapsed=174.42 sec\n",
            "16\n",
            "13\n",
            "12\n",
            "14\n",
            "14\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "epoch 10 (1/272) | step 2450 | avg_nll=16.39 avg_ppl=9.92 speed=2786.69 words/sec time_elapsed=175.24 sec\n",
            "14\n",
            "12\n",
            "15\n",
            "12\n",
            "17\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "16\n",
            "epoch 10 (11/272) | step 2460 | avg_nll=16.65 avg_ppl=9.77 speed=3847.24 words/sec time_elapsed=175.85 sec\n",
            "13\n",
            "12\n",
            "11\n",
            "12\n",
            "14\n",
            "13\n",
            "13\n",
            "14\n",
            "12\n",
            "15\n",
            "epoch 10 (21/272) | step 2470 | avg_nll=15.40 avg_ppl=8.64 speed=3983.98 words/sec time_elapsed=176.42 sec\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "12\n",
            "12\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "epoch 10 (31/272) | step 2480 | avg_nll=16.08 avg_ppl=9.11 speed=4156.36 words/sec time_elapsed=176.98 sec\n",
            "16\n",
            "13\n",
            "13\n",
            "12\n",
            "15\n",
            "12\n",
            "11\n",
            "12\n",
            "12\n",
            "15\n",
            "epoch 10 (41/272) | step 2490 | avg_nll=15.41 avg_ppl=8.61 speed=3874.95 words/sec time_elapsed=177.57 sec\n",
            "12\n",
            "13\n",
            "12\n",
            "14\n",
            "15\n",
            "12\n",
            "12\n",
            "15\n",
            "15\n",
            "13\n",
            "epoch 10 (51/272) | step 2500 | avg_nll=15.71 avg_ppl=8.90 speed=3684.58 words/sec time_elapsed=178.20 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 2500 | dev_ppl=11.53085994720459\n",
            "epoch 10 step 2500: save currently the best model to 'model.pt'\n",
            "13\n",
            "13\n",
            "13\n",
            "17\n",
            "12\n",
            "14\n",
            "14\n",
            "15\n",
            "14\n",
            "12\n",
            "epoch 10 (61/272) | step 2510 | avg_nll=16.79 avg_ppl=9.80 speed=2546.69 words/sec time_elapsed=179.12 sec\n",
            "13\n",
            "14\n",
            "12\n",
            "15\n",
            "12\n",
            "14\n",
            "13\n",
            "17\n",
            "13\n",
            "15\n",
            "epoch 10 (71/272) | step 2520 | avg_nll=15.59 avg_ppl=8.56 speed=3950.04 words/sec time_elapsed=179.71 sec\n",
            "12\n",
            "13\n",
            "15\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "epoch 10 (81/272) | step 2530 | avg_nll=15.29 avg_ppl=8.12 speed=4064.67 words/sec time_elapsed=180.29 sec\n",
            "13\n",
            "14\n",
            "12\n",
            "15\n",
            "13\n",
            "14\n",
            "13\n",
            "11\n",
            "14\n",
            "13\n",
            "epoch 10 (91/272) | step 2540 | avg_nll=15.81 avg_ppl=9.00 speed=3892.22 words/sec time_elapsed=180.88 sec\n",
            "16\n",
            "13\n",
            "15\n",
            "13\n",
            "12\n",
            "15\n",
            "15\n",
            "14\n",
            "13\n",
            "17\n",
            "epoch 10 (101/272) | step 2550 | avg_nll=16.25 avg_ppl=9.27 speed=3979.59 words/sec time_elapsed=181.46 sec\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "17\n",
            "14\n",
            "13\n",
            "13\n",
            "epoch 10 (111/272) | step 2560 | avg_nll=15.32 avg_ppl=8.32 speed=3965.27 words/sec time_elapsed=182.05 sec\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "12\n",
            "14\n",
            "13\n",
            "13\n",
            "14\n",
            "12\n",
            "epoch 10 (121/272) | step 2570 | avg_nll=15.78 avg_ppl=9.18 speed=3935.73 words/sec time_elapsed=182.63 sec\n",
            "13\n",
            "14\n",
            "11\n",
            "13\n",
            "14\n",
            "14\n",
            "15\n",
            "14\n",
            "16\n",
            "13\n",
            "epoch 10 (131/272) | step 2580 | avg_nll=16.96 avg_ppl=9.90 speed=3903.25 words/sec time_elapsed=183.23 sec\n",
            "15\n",
            "12\n",
            "14\n",
            "13\n",
            "14\n",
            "12\n",
            "14\n",
            "16\n",
            "13\n",
            "13\n",
            "epoch 10 (141/272) | step 2590 | avg_nll=17.03 avg_ppl=10.46 speed=4037.14 words/sec time_elapsed=183.81 sec\n",
            "14\n",
            "13\n",
            "17\n",
            "14\n",
            "14\n",
            "15\n",
            "13\n",
            "15\n",
            "14\n",
            "13\n",
            "epoch 10 (151/272) | step 2600 | avg_nll=16.43 avg_ppl=9.52 speed=3834.70 words/sec time_elapsed=184.42 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 2600 | dev_ppl=11.432462692260742\n",
            "epoch 10 step 2600: save currently the best model to 'model.pt'\n",
            "12\n",
            "16\n",
            "14\n",
            "14\n",
            "14\n",
            "12\n",
            "14\n",
            "13\n",
            "15\n",
            "15\n",
            "epoch 10 (161/272) | step 2610 | avg_nll=15.33 avg_ppl=8.12 speed=2262.27 words/sec time_elapsed=185.45 sec\n",
            "12\n",
            "13\n",
            "13\n",
            "14\n",
            "12\n",
            "14\n",
            "14\n",
            "14\n",
            "15\n",
            "13\n",
            "epoch 10 (171/272) | step 2620 | avg_nll=16.13 avg_ppl=9.24 speed=2696.91 words/sec time_elapsed=186.31 sec\n",
            "12\n",
            "13\n",
            "12\n",
            "15\n",
            "13\n",
            "14\n",
            "15\n",
            "15\n",
            "15\n",
            "13\n",
            "epoch 10 (181/272) | step 2630 | avg_nll=15.36 avg_ppl=8.49 speed=2690.88 words/sec time_elapsed=187.17 sec\n",
            "14\n",
            "14\n",
            "12\n",
            "15\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "16\n",
            "epoch 10 (191/272) | step 2640 | avg_nll=16.90 avg_ppl=10.54 speed=2606.69 words/sec time_elapsed=188.05 sec\n",
            "14\n",
            "15\n",
            "16\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 10 (201/272) | step 2650 | avg_nll=15.63 avg_ppl=8.74 speed=2758.07 words/sec time_elapsed=188.89 sec\n",
            "11\n",
            "13\n",
            "15\n",
            "14\n",
            "12\n",
            "12\n",
            "15\n",
            "12\n",
            "14\n",
            "13\n",
            "epoch 10 (211/272) | step 2660 | avg_nll=15.37 avg_ppl=8.71 speed=3767.31 words/sec time_elapsed=189.49 sec\n",
            "12\n",
            "14\n",
            "12\n",
            "15\n",
            "15\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "12\n",
            "epoch 10 (221/272) | step 2670 | avg_nll=15.24 avg_ppl=8.01 speed=3810.18 words/sec time_elapsed=190.11 sec\n",
            "11\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "14\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "epoch 10 (231/272) | step 2680 | avg_nll=15.97 avg_ppl=9.31 speed=3852.60 words/sec time_elapsed=190.70 sec\n",
            "13\n",
            "12\n",
            "15\n",
            "14\n",
            "13\n",
            "16\n",
            "16\n",
            "14\n",
            "15\n",
            "11\n",
            "epoch 10 (241/272) | step 2690 | avg_nll=16.20 avg_ppl=9.44 speed=4056.12 words/sec time_elapsed=191.27 sec\n",
            "13\n",
            "15\n",
            "12\n",
            "15\n",
            "12\n",
            "14\n",
            "12\n",
            "12\n",
            "14\n",
            "12\n",
            "epoch 10 (251/272) | step 2700 | avg_nll=17.05 avg_ppl=10.34 speed=3962.37 words/sec time_elapsed=191.86 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 2700 | dev_ppl=10.941781044006348\n",
            "epoch 10 step 2700: save currently the best model to 'model.pt'\n",
            "15\n",
            "17\n",
            "16\n",
            "13\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "12\n",
            "13\n",
            "epoch 10 (261/272) | step 2710 | avg_nll=17.24 avg_ppl=10.23 speed=2578.07 words/sec time_elapsed=192.78 sec\n",
            "14\n",
            "15\n",
            "13\n",
            "15\n",
            "13\n",
            "12\n",
            "14\n",
            "18\n",
            "14\n",
            "14\n",
            "epoch 10 (271/272) | step 2720 | avg_nll=15.81 avg_ppl=9.25 speed=3943.03 words/sec time_elapsed=193.36 sec\n",
            "13\n",
            "15\n",
            "14\n",
            "14\n",
            "17\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "15\n",
            "epoch 11 (9/272) | step 2730 | avg_nll=15.89 avg_ppl=8.68 speed=3954.54 words/sec time_elapsed=193.95 sec\n",
            "14\n",
            "12\n",
            "17\n",
            "13\n",
            "15\n",
            "11\n",
            "12\n",
            "13\n",
            "12\n",
            "12\n",
            "epoch 11 (19/272) | step 2740 | avg_nll=14.58 avg_ppl=7.92 speed=3841.62 words/sec time_elapsed=194.54 sec\n",
            "14\n",
            "15\n",
            "14\n",
            "12\n",
            "13\n",
            "15\n",
            "14\n",
            "14\n",
            "13\n",
            "12\n",
            "epoch 11 (29/272) | step 2750 | avg_nll=15.51 avg_ppl=8.61 speed=4055.10 words/sec time_elapsed=195.11 sec\n",
            "13\n",
            "13\n",
            "12\n",
            "14\n",
            "14\n",
            "15\n",
            "14\n",
            "15\n",
            "13\n",
            "14\n",
            "epoch 11 (39/272) | step 2760 | avg_nll=14.82 avg_ppl=7.73 speed=4050.68 words/sec time_elapsed=195.68 sec\n",
            "15\n",
            "15\n",
            "13\n",
            "15\n",
            "12\n",
            "13\n",
            "13\n",
            "15\n",
            "12\n",
            "13\n",
            "epoch 11 (49/272) | step 2770 | avg_nll=16.13 avg_ppl=9.34 speed=3828.94 words/sec time_elapsed=196.28 sec\n",
            "12\n",
            "14\n",
            "15\n",
            "12\n",
            "13\n",
            "16\n",
            "13\n",
            "14\n",
            "12\n",
            "15\n",
            "epoch 11 (59/272) | step 2780 | avg_nll=14.82 avg_ppl=7.90 speed=3900.52 words/sec time_elapsed=196.87 sec\n",
            "13\n",
            "11\n",
            "15\n",
            "12\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "14\n",
            "16\n",
            "epoch 11 (69/272) | step 2790 | avg_nll=16.49 avg_ppl=9.80 speed=3853.51 words/sec time_elapsed=197.47 sec\n",
            "15\n",
            "12\n",
            "14\n",
            "13\n",
            "11\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "epoch 11 (79/272) | step 2800 | avg_nll=14.71 avg_ppl=7.64 speed=4042.42 words/sec time_elapsed=198.04 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 2800 | dev_ppl=10.880707740783691\n",
            "epoch 11 step 2800: save currently the best model to 'model.pt'\n",
            "12\n",
            "12\n",
            "17\n",
            "15\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "epoch 11 (89/272) | step 2810 | avg_nll=15.10 avg_ppl=8.16 speed=2107.81 words/sec time_elapsed=199.14 sec\n",
            "17\n",
            "14\n",
            "13\n",
            "15\n",
            "15\n",
            "13\n",
            "13\n",
            "16\n",
            "14\n",
            "14\n",
            "epoch 11 (99/272) | step 2820 | avg_nll=15.17 avg_ppl=8.20 speed=2725.38 words/sec time_elapsed=199.98 sec\n",
            "14\n",
            "14\n",
            "13\n",
            "12\n",
            "14\n",
            "14\n",
            "12\n",
            "12\n",
            "13\n",
            "14\n",
            "epoch 11 (109/272) | step 2830 | avg_nll=15.26 avg_ppl=8.31 speed=2829.03 words/sec time_elapsed=200.80 sec\n",
            "15\n",
            "15\n",
            "14\n",
            "17\n",
            "12\n",
            "13\n",
            "15\n",
            "12\n",
            "14\n",
            "15\n",
            "epoch 11 (119/272) | step 2840 | avg_nll=16.06 avg_ppl=9.24 speed=2522.03 words/sec time_elapsed=201.72 sec\n",
            "14\n",
            "14\n",
            "14\n",
            "14\n",
            "16\n",
            "13\n",
            "15\n",
            "16\n",
            "12\n",
            "15\n",
            "epoch 11 (129/272) | step 2850 | avg_nll=15.65 avg_ppl=8.35 speed=2925.93 words/sec time_elapsed=202.52 sec\n",
            "14\n",
            "11\n",
            "18\n",
            "12\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "epoch 11 (139/272) | step 2860 | avg_nll=15.45 avg_ppl=8.48 speed=3779.33 words/sec time_elapsed=203.13 sec\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "13\n",
            "12\n",
            "12\n",
            "13\n",
            "13\n",
            "15\n",
            "epoch 11 (149/272) | step 2870 | avg_nll=14.48 avg_ppl=7.43 speed=3917.49 words/sec time_elapsed=203.72 sec\n",
            "14\n",
            "14\n",
            "13\n",
            "15\n",
            "13\n",
            "14\n",
            "16\n",
            "13\n",
            "15\n",
            "15\n",
            "epoch 11 (159/272) | step 2880 | avg_nll=16.11 avg_ppl=9.07 speed=3806.09 words/sec time_elapsed=204.34 sec\n",
            "13\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "12\n",
            "epoch 11 (169/272) | step 2890 | avg_nll=15.16 avg_ppl=7.94 speed=3745.35 words/sec time_elapsed=204.96 sec\n",
            "13\n",
            "12\n",
            "13\n",
            "12\n",
            "14\n",
            "14\n",
            "16\n",
            "13\n",
            "11\n",
            "15\n",
            "epoch 11 (179/272) | step 2900 | avg_nll=14.71 avg_ppl=7.75 speed=3658.83 words/sec time_elapsed=205.59 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 2900 | dev_ppl=10.702720642089844\n",
            "epoch 11 step 2900: save currently the best model to 'model.pt'\n",
            "12\n",
            "14\n",
            "12\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "11\n",
            "epoch 11 (189/272) | step 2910 | avg_nll=14.64 avg_ppl=7.62 speed=2379.15 words/sec time_elapsed=206.56 sec\n",
            "15\n",
            "12\n",
            "15\n",
            "14\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "15\n",
            "14\n",
            "epoch 11 (199/272) | step 2920 | avg_nll=16.26 avg_ppl=9.20 speed=3609.36 words/sec time_elapsed=207.21 sec\n",
            "14\n",
            "14\n",
            "12\n",
            "13\n",
            "15\n",
            "12\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "epoch 11 (209/272) | step 2930 | avg_nll=15.92 avg_ppl=8.59 speed=4116.00 words/sec time_elapsed=207.79 sec\n",
            "13\n",
            "13\n",
            "15\n",
            "13\n",
            "14\n",
            "13\n",
            "17\n",
            "14\n",
            "14\n",
            "11\n",
            "epoch 11 (219/272) | step 2940 | avg_nll=14.64 avg_ppl=7.42 speed=3699.60 words/sec time_elapsed=208.42 sec\n",
            "13\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "14\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "epoch 11 (229/272) | step 2950 | avg_nll=14.43 avg_ppl=7.37 speed=3710.16 words/sec time_elapsed=209.04 sec\n",
            "14\n",
            "14\n",
            "16\n",
            "16\n",
            "13\n",
            "12\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "epoch 11 (239/272) | step 2960 | avg_nll=16.23 avg_ppl=9.14 speed=3746.06 words/sec time_elapsed=209.67 sec\n",
            "13\n",
            "15\n",
            "14\n",
            "15\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "16\n",
            "epoch 11 (249/272) | step 2970 | avg_nll=15.90 avg_ppl=9.02 speed=3937.58 words/sec time_elapsed=210.26 sec\n",
            "13\n",
            "15\n",
            "14\n",
            "16\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "epoch 11 (259/272) | step 2980 | avg_nll=14.47 avg_ppl=7.47 speed=3833.96 words/sec time_elapsed=210.86 sec\n",
            "13\n",
            "14\n",
            "13\n",
            "17\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "12\n",
            "13\n",
            "epoch 11 (269/272) | step 2990 | avg_nll=15.60 avg_ppl=8.84 speed=3669.03 words/sec time_elapsed=211.48 sec\n",
            "13\n",
            "13\n",
            "13\n",
            "15\n",
            "15\n",
            "14\n",
            "17\n",
            "14\n",
            "13\n",
            "17\n",
            "epoch 12 (7/272) | step 3000 | avg_nll=15.12 avg_ppl=8.11 speed=3644.47 words/sec time_elapsed=212.12 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 3000 | dev_ppl=10.614697456359863\n",
            "epoch 12 step 3000: save currently the best model to 'model.pt'\n",
            "14\n",
            "13\n",
            "16\n",
            "15\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "12\n",
            "15\n",
            "epoch 12 (17/272) | step 3010 | avg_nll=14.19 avg_ppl=7.32 speed=1828.63 words/sec time_elapsed=213.37 sec\n",
            "13\n",
            "13\n",
            "14\n",
            "12\n",
            "17\n",
            "18\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "epoch 12 (27/272) | step 3020 | avg_nll=15.12 avg_ppl=8.26 speed=2672.93 words/sec time_elapsed=214.22 sec\n",
            "13\n",
            "15\n",
            "14\n",
            "15\n",
            "15\n",
            "16\n",
            "14\n",
            "12\n",
            "13\n",
            "13\n",
            "epoch 12 (37/272) | step 3030 | avg_nll=15.35 avg_ppl=8.15 speed=2550.46 words/sec time_elapsed=215.14 sec\n",
            "12\n",
            "12\n",
            "14\n",
            "15\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "14\n",
            "14\n",
            "epoch 12 (47/272) | step 3040 | avg_nll=14.48 avg_ppl=7.33 speed=2635.95 words/sec time_elapsed=216.03 sec\n",
            "12\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "15\n",
            "12\n",
            "16\n",
            "14\n",
            "11\n",
            "epoch 12 (57/272) | step 3050 | avg_nll=14.69 avg_ppl=7.35 speed=3862.79 words/sec time_elapsed=216.64 sec\n",
            "15\n",
            "11\n",
            "14\n",
            "13\n",
            "11\n",
            "15\n",
            "14\n",
            "13\n",
            "12\n",
            "12\n",
            "epoch 12 (67/272) | step 3060 | avg_nll=15.19 avg_ppl=8.14 speed=3954.49 words/sec time_elapsed=217.22 sec\n",
            "12\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "17\n",
            "15\n",
            "14\n",
            "12\n",
            "epoch 12 (77/272) | step 3070 | avg_nll=15.38 avg_ppl=8.23 speed=3727.69 words/sec time_elapsed=217.85 sec\n",
            "14\n",
            "12\n",
            "11\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "15\n",
            "epoch 12 (87/272) | step 3080 | avg_nll=14.33 avg_ppl=7.11 speed=3816.22 words/sec time_elapsed=218.46 sec\n",
            "13\n",
            "16\n",
            "12\n",
            "11\n",
            "12\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "11\n",
            "epoch 12 (97/272) | step 3090 | avg_nll=14.56 avg_ppl=7.67 speed=3817.27 words/sec time_elapsed=219.06 sec\n",
            "13\n",
            "14\n",
            "14\n",
            "15\n",
            "14\n",
            "16\n",
            "13\n",
            "14\n",
            "14\n",
            "16\n",
            "epoch 12 (107/272) | step 3100 | avg_nll=15.25 avg_ppl=8.16 speed=3823.00 words/sec time_elapsed=219.67 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 3100 | dev_ppl=10.322881698608398\n",
            "epoch 12 step 3100: save currently the best model to 'model.pt'\n",
            "12\n",
            "14\n",
            "13\n",
            "13\n",
            "12\n",
            "15\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "epoch 12 (117/272) | step 3110 | avg_nll=14.14 avg_ppl=7.16 speed=2402.40 words/sec time_elapsed=220.63 sec\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "15\n",
            "13\n",
            "15\n",
            "13\n",
            "16\n",
            "14\n",
            "epoch 12 (127/272) | step 3120 | avg_nll=14.83 avg_ppl=7.90 speed=3797.91 words/sec time_elapsed=221.23 sec\n",
            "14\n",
            "14\n",
            "12\n",
            "14\n",
            "11\n",
            "15\n",
            "13\n",
            "13\n",
            "13\n",
            "14\n",
            "epoch 12 (137/272) | step 3130 | avg_nll=13.57 avg_ppl=6.67 speed=3866.43 words/sec time_elapsed=221.82 sec\n",
            "16\n",
            "14\n",
            "14\n",
            "14\n",
            "16\n",
            "15\n",
            "14\n",
            "16\n",
            "13\n",
            "12\n",
            "epoch 12 (147/272) | step 3140 | avg_nll=14.45 avg_ppl=7.43 speed=3919.11 words/sec time_elapsed=222.41 sec\n",
            "12\n",
            "14\n",
            "13\n",
            "15\n",
            "15\n",
            "14\n",
            "13\n",
            "12\n",
            "11\n",
            "14\n",
            "epoch 12 (157/272) | step 3150 | avg_nll=14.64 avg_ppl=7.33 speed=3650.94 words/sec time_elapsed=223.06 sec\n",
            "13\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "12\n",
            "15\n",
            "13\n",
            "14\n",
            "12\n",
            "epoch 12 (167/272) | step 3160 | avg_nll=15.10 avg_ppl=7.72 speed=3961.12 words/sec time_elapsed=223.65 sec\n",
            "12\n",
            "12\n",
            "12\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "epoch 12 (177/272) | step 3170 | avg_nll=14.84 avg_ppl=7.69 speed=3932.88 words/sec time_elapsed=224.25 sec\n",
            "14\n",
            "17\n",
            "14\n",
            "15\n",
            "13\n",
            "12\n",
            "14\n",
            "15\n",
            "14\n",
            "14\n",
            "epoch 12 (187/272) | step 3180 | avg_nll=14.74 avg_ppl=7.42 speed=3928.65 words/sec time_elapsed=224.84 sec\n",
            "14\n",
            "12\n",
            "12\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "13\n",
            "13\n",
            "15\n",
            "epoch 12 (197/272) | step 3190 | avg_nll=15.03 avg_ppl=7.96 speed=3995.29 words/sec time_elapsed=225.43 sec\n",
            "14\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "12\n",
            "12\n",
            "14\n",
            "13\n",
            "13\n",
            "epoch 12 (207/272) | step 3200 | avg_nll=13.65 avg_ppl=6.81 speed=3765.31 words/sec time_elapsed=226.03 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 3200 | dev_ppl=10.107994079589844\n",
            "epoch 12 step 3200: save currently the best model to 'model.pt'\n",
            "17\n",
            "12\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "15\n",
            "12\n",
            "12\n",
            "14\n",
            "epoch 12 (217/272) | step 3210 | avg_nll=14.28 avg_ppl=7.29 speed=1765.18 words/sec time_elapsed=227.33 sec\n",
            "14\n",
            "13\n",
            "15\n",
            "14\n",
            "14\n",
            "15\n",
            "12\n",
            "15\n",
            "15\n",
            "12\n",
            "epoch 12 (227/272) | step 3220 | avg_nll=14.95 avg_ppl=7.77 speed=2557.75 words/sec time_elapsed=228.25 sec\n",
            "16\n",
            "12\n",
            "14\n",
            "15\n",
            "15\n",
            "14\n",
            "12\n",
            "17\n",
            "12\n",
            "12\n",
            "epoch 12 (237/272) | step 3230 | avg_nll=14.91 avg_ppl=7.86 speed=2556.50 words/sec time_elapsed=229.15 sec\n",
            "14\n",
            "14\n",
            "14\n",
            "14\n",
            "15\n",
            "12\n",
            "13\n",
            "15\n",
            "13\n",
            "14\n",
            "epoch 12 (247/272) | step 3240 | avg_nll=14.83 avg_ppl=7.65 speed=2713.23 words/sec time_elapsed=230.01 sec\n",
            "14\n",
            "15\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "13\n",
            "epoch 12 (257/272) | step 3250 | avg_nll=15.28 avg_ppl=8.40 speed=3624.49 words/sec time_elapsed=230.65 sec\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "13\n",
            "15\n",
            "15\n",
            "14\n",
            "11\n",
            "epoch 12 (267/272) | step 3260 | avg_nll=14.49 avg_ppl=7.63 speed=3845.77 words/sec time_elapsed=231.24 sec\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "16\n",
            "14\n",
            "14\n",
            "epoch 13 (5/272) | step 3270 | avg_nll=14.11 avg_ppl=7.16 speed=4083.36 words/sec time_elapsed=231.80 sec\n",
            "15\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "15\n",
            "12\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 13 (15/272) | step 3280 | avg_nll=12.98 avg_ppl=5.99 speed=3776.83 words/sec time_elapsed=232.42 sec\n",
            "12\n",
            "11\n",
            "12\n",
            "14\n",
            "14\n",
            "12\n",
            "14\n",
            "14\n",
            "12\n",
            "14\n",
            "epoch 13 (25/272) | step 3290 | avg_nll=14.06 avg_ppl=7.05 speed=3989.96 words/sec time_elapsed=232.99 sec\n",
            "13\n",
            "15\n",
            "13\n",
            "14\n",
            "17\n",
            "17\n",
            "13\n",
            "14\n",
            "13\n",
            "15\n",
            "epoch 13 (35/272) | step 3300 | avg_nll=13.99 avg_ppl=6.93 speed=3781.88 words/sec time_elapsed=233.61 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 3300 | dev_ppl=10.071595191955566\n",
            "epoch 13 step 3300: save currently the best model to 'model.pt'\n",
            "13\n",
            "14\n",
            "14\n",
            "15\n",
            "16\n",
            "14\n",
            "12\n",
            "16\n",
            "13\n",
            "14\n",
            "epoch 13 (45/272) | step 3310 | avg_nll=14.60 avg_ppl=7.30 speed=2464.48 words/sec time_elapsed=234.56 sec\n",
            "13\n",
            "12\n",
            "14\n",
            "14\n",
            "14\n",
            "15\n",
            "12\n",
            "14\n",
            "15\n",
            "14\n",
            "epoch 13 (55/272) | step 3320 | avg_nll=13.79 avg_ppl=6.92 speed=3599.19 words/sec time_elapsed=235.19 sec\n",
            "13\n",
            "13\n",
            "15\n",
            "11\n",
            "15\n",
            "15\n",
            "12\n",
            "14\n",
            "13\n",
            "14\n",
            "epoch 13 (65/272) | step 3330 | avg_nll=14.13 avg_ppl=7.13 speed=3828.32 words/sec time_elapsed=235.79 sec\n",
            "15\n",
            "14\n",
            "17\n",
            "17\n",
            "14\n",
            "15\n",
            "12\n",
            "13\n",
            "14\n",
            "17\n",
            "epoch 13 (75/272) | step 3340 | avg_nll=14.44 avg_ppl=7.21 speed=3759.96 words/sec time_elapsed=236.42 sec\n",
            "14\n",
            "12\n",
            "11\n",
            "12\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 13 (85/272) | step 3350 | avg_nll=14.50 avg_ppl=7.25 speed=3941.73 words/sec time_elapsed=237.01 sec\n",
            "14\n",
            "13\n",
            "15\n",
            "12\n",
            "14\n",
            "12\n",
            "14\n",
            "14\n",
            "13\n",
            "15\n",
            "epoch 13 (95/272) | step 3360 | avg_nll=13.67 avg_ppl=6.75 speed=3755.04 words/sec time_elapsed=237.62 sec\n",
            "13\n",
            "14\n",
            "18\n",
            "14\n",
            "14\n",
            "13\n",
            "15\n",
            "15\n",
            "14\n",
            "14\n",
            "epoch 13 (105/272) | step 3370 | avg_nll=14.62 avg_ppl=7.33 speed=3724.18 words/sec time_elapsed=238.25 sec\n",
            "15\n",
            "12\n",
            "14\n",
            "14\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 13 (115/272) | step 3380 | avg_nll=14.00 avg_ppl=6.64 speed=4128.15 words/sec time_elapsed=238.83 sec\n",
            "11\n",
            "13\n",
            "13\n",
            "15\n",
            "15\n",
            "14\n",
            "16\n",
            "13\n",
            "12\n",
            "13\n",
            "epoch 13 (125/272) | step 3390 | avg_nll=14.22 avg_ppl=7.09 speed=4060.64 words/sec time_elapsed=239.40 sec\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "epoch 13 (135/272) | step 3400 | avg_nll=14.20 avg_ppl=7.08 speed=3449.65 words/sec time_elapsed=240.07 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 3400 | dev_ppl=10.070185661315918\n",
            "epoch 13 step 3400: save currently the best model to 'model.pt'\n",
            "12\n",
            "15\n",
            "11\n",
            "13\n",
            "15\n",
            "14\n",
            "12\n",
            "12\n",
            "15\n",
            "13\n",
            "epoch 13 (145/272) | step 3410 | avg_nll=13.95 avg_ppl=6.94 speed=1722.15 words/sec time_elapsed=241.41 sec\n",
            "14\n",
            "13\n",
            "13\n",
            "15\n",
            "14\n",
            "14\n",
            "15\n",
            "13\n",
            "14\n",
            "11\n",
            "epoch 13 (155/272) | step 3420 | avg_nll=14.21 avg_ppl=6.98 speed=2565.17 words/sec time_elapsed=242.33 sec\n",
            "13\n",
            "12\n",
            "15\n",
            "14\n",
            "12\n",
            "16\n",
            "13\n",
            "12\n",
            "14\n",
            "13\n",
            "epoch 13 (165/272) | step 3430 | avg_nll=12.70 avg_ppl=5.96 speed=2689.36 words/sec time_elapsed=243.17 sec\n",
            "12\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "epoch 13 (175/272) | step 3440 | avg_nll=15.25 avg_ppl=8.00 speed=3166.78 words/sec time_elapsed=243.91 sec\n",
            "16\n",
            "13\n",
            "12\n",
            "17\n",
            "12\n",
            "13\n",
            "16\n",
            "12\n",
            "13\n",
            "15\n",
            "epoch 13 (185/272) | step 3450 | avg_nll=14.03 avg_ppl=7.02 speed=4047.00 words/sec time_elapsed=244.48 sec\n",
            "14\n",
            "12\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "12\n",
            "epoch 13 (195/272) | step 3460 | avg_nll=13.42 avg_ppl=6.57 speed=3895.75 words/sec time_elapsed=245.07 sec\n",
            "11\n",
            "15\n",
            "13\n",
            "11\n",
            "14\n",
            "14\n",
            "11\n",
            "13\n",
            "14\n",
            "13\n",
            "epoch 13 (205/272) | step 3470 | avg_nll=13.34 avg_ppl=6.41 speed=3698.49 words/sec time_elapsed=245.69 sec\n",
            "12\n",
            "15\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "14\n",
            "epoch 13 (215/272) | step 3480 | avg_nll=13.16 avg_ppl=6.48 speed=3889.12 words/sec time_elapsed=246.27 sec\n",
            "15\n",
            "13\n",
            "13\n",
            "12\n",
            "14\n",
            "14\n",
            "12\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 13 (225/272) | step 3490 | avg_nll=15.05 avg_ppl=7.82 speed=3841.06 words/sec time_elapsed=246.88 sec\n",
            "16\n",
            "14\n",
            "14\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "12\n",
            "15\n",
            "13\n",
            "epoch 13 (235/272) | step 3500 | avg_nll=14.57 avg_ppl=7.51 speed=3899.06 words/sec time_elapsed=247.47 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 3500 | dev_ppl=9.867836952209473\n",
            "epoch 13 step 3500: save currently the best model to 'model.pt'\n",
            "13\n",
            "15\n",
            "14\n",
            "12\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "epoch 13 (245/272) | step 3510 | avg_nll=15.02 avg_ppl=7.84 speed=2504.22 words/sec time_elapsed=248.40 sec\n",
            "16\n",
            "13\n",
            "12\n",
            "15\n",
            "17\n",
            "12\n",
            "15\n",
            "13\n",
            "13\n",
            "16\n",
            "epoch 13 (255/272) | step 3520 | avg_nll=13.68 avg_ppl=6.42 speed=3813.56 words/sec time_elapsed=249.02 sec\n",
            "15\n",
            "15\n",
            "14\n",
            "14\n",
            "14\n",
            "12\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "epoch 13 (265/272) | step 3530 | avg_nll=14.16 avg_ppl=7.07 speed=3933.63 words/sec time_elapsed=249.61 sec\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "15\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "epoch 14 (3/272) | step 3540 | avg_nll=12.84 avg_ppl=6.00 speed=3903.21 words/sec time_elapsed=250.20 sec\n",
            "15\n",
            "14\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "14\n",
            "15\n",
            "15\n",
            "14\n",
            "epoch 14 (13/272) | step 3550 | avg_nll=14.21 avg_ppl=7.06 speed=3858.75 words/sec time_elapsed=250.80 sec\n",
            "14\n",
            "16\n",
            "15\n",
            "13\n",
            "13\n",
            "13\n",
            "11\n",
            "13\n",
            "13\n",
            "15\n",
            "epoch 14 (23/272) | step 3560 | avg_nll=13.46 avg_ppl=6.51 speed=3928.59 words/sec time_elapsed=251.39 sec\n",
            "13\n",
            "14\n",
            "14\n",
            "12\n",
            "15\n",
            "14\n",
            "12\n",
            "14\n",
            "12\n",
            "16\n",
            "epoch 14 (33/272) | step 3570 | avg_nll=13.67 avg_ppl=6.38 speed=3945.12 words/sec time_elapsed=251.99 sec\n",
            "14\n",
            "14\n",
            "15\n",
            "13\n",
            "14\n",
            "15\n",
            "13\n",
            "15\n",
            "16\n",
            "15\n",
            "epoch 14 (43/272) | step 3580 | avg_nll=13.36 avg_ppl=6.47 speed=3671.38 words/sec time_elapsed=252.61 sec\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "16\n",
            "14\n",
            "14\n",
            "17\n",
            "13\n",
            "16\n",
            "epoch 14 (53/272) | step 3590 | avg_nll=13.95 avg_ppl=6.78 speed=3937.03 words/sec time_elapsed=253.20 sec\n",
            "14\n",
            "13\n",
            "12\n",
            "15\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "13\n",
            "18\n",
            "epoch 14 (63/272) | step 3600 | avg_nll=14.17 avg_ppl=6.78 speed=3414.32 words/sec time_elapsed=253.90 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 3600 | dev_ppl=9.813042640686035\n",
            "epoch 14 step 3600: save currently the best model to 'model.pt'\n",
            "12\n",
            "14\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "16\n",
            "17\n",
            "13\n",
            "epoch 14 (73/272) | step 3610 | avg_nll=13.61 avg_ppl=6.73 speed=1460.82 words/sec time_elapsed=255.46 sec\n",
            "14\n",
            "15\n",
            "13\n",
            "12\n",
            "11\n",
            "15\n",
            "13\n",
            "14\n",
            "14\n",
            "17\n",
            "epoch 14 (83/272) | step 3620 | avg_nll=13.74 avg_ppl=6.72 speed=2283.87 words/sec time_elapsed=256.47 sec\n",
            "13\n",
            "14\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "11\n",
            "13\n",
            "epoch 14 (93/272) | step 3630 | avg_nll=13.18 avg_ppl=6.17 speed=2377.87 words/sec time_elapsed=257.45 sec\n",
            "11\n",
            "14\n",
            "14\n",
            "14\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "14\n",
            "14\n",
            "epoch 14 (103/272) | step 3640 | avg_nll=13.70 avg_ppl=6.64 speed=2247.35 words/sec time_elapsed=258.48 sec\n",
            "12\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "13\n",
            "15\n",
            "14\n",
            "14\n",
            "12\n",
            "epoch 14 (113/272) | step 3650 | avg_nll=13.83 avg_ppl=6.54 speed=2270.34 words/sec time_elapsed=259.52 sec\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "15\n",
            "15\n",
            "13\n",
            "13\n",
            "14\n",
            "epoch 14 (123/272) | step 3660 | avg_nll=13.98 avg_ppl=6.86 speed=1824.96 words/sec time_elapsed=260.79 sec\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "12\n",
            "15\n",
            "12\n",
            "15\n",
            "12\n",
            "12\n",
            "epoch 14 (133/272) | step 3670 | avg_nll=13.60 avg_ppl=6.60 speed=2940.01 words/sec time_elapsed=261.58 sec\n",
            "13\n",
            "12\n",
            "15\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "14\n",
            "15\n",
            "epoch 14 (143/272) | step 3680 | avg_nll=12.85 avg_ppl=5.81 speed=2457.54 words/sec time_elapsed=262.53 sec\n",
            "15\n",
            "11\n",
            "14\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "13\n",
            "11\n",
            "epoch 14 (153/272) | step 3690 | avg_nll=13.40 avg_ppl=6.18 speed=2250.03 words/sec time_elapsed=263.58 sec\n",
            "15\n",
            "15\n",
            "14\n",
            "13\n",
            "15\n",
            "14\n",
            "12\n",
            "13\n",
            "13\n",
            "15\n",
            "epoch 14 (163/272) | step 3700 | avg_nll=13.80 avg_ppl=6.64 speed=1774.78 words/sec time_elapsed=264.89 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 3700 | dev_ppl=9.855786323547363\n",
            "14\n",
            "17\n",
            "15\n",
            "11\n",
            "14\n",
            "12\n",
            "12\n",
            "14\n",
            "15\n",
            "14\n",
            "epoch 14 (173/272) | step 3710 | avg_nll=14.04 avg_ppl=6.77 speed=1157.35 words/sec time_elapsed=266.92 sec\n",
            "12\n",
            "13\n",
            "16\n",
            "15\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "epoch 14 (183/272) | step 3720 | avg_nll=13.89 avg_ppl=6.77 speed=1774.32 words/sec time_elapsed=268.24 sec\n",
            "12\n",
            "13\n",
            "15\n",
            "14\n",
            "12\n",
            "14\n",
            "13\n",
            "14\n",
            "11\n",
            "13\n",
            "epoch 14 (193/272) | step 3730 | avg_nll=13.78 avg_ppl=6.82 speed=1402.75 words/sec time_elapsed=269.87 sec\n",
            "13\n",
            "13\n",
            "12\n",
            "16\n",
            "14\n",
            "12\n",
            "16\n",
            "16\n",
            "13\n",
            "15\n",
            "epoch 14 (203/272) | step 3740 | avg_nll=12.47 avg_ppl=5.76 speed=934.83 words/sec time_elapsed=272.32 sec\n",
            "13\n",
            "14\n",
            "13\n",
            "17\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "11\n",
            "13\n",
            "epoch 14 (213/272) | step 3750 | avg_nll=13.37 avg_ppl=6.62 speed=956.73 words/sec time_elapsed=274.69 sec\n",
            "14\n",
            "13\n",
            "13\n",
            "12\n",
            "13\n",
            "13\n",
            "15\n",
            "16\n",
            "14\n",
            "14\n",
            "epoch 14 (223/272) | step 3760 | avg_nll=13.52 avg_ppl=6.57 speed=1953.14 words/sec time_elapsed=275.87 sec\n",
            "13\n",
            "14\n",
            "13\n",
            "15\n",
            "14\n",
            "14\n",
            "17\n",
            "15\n",
            "14\n",
            "13\n",
            "epoch 14 (233/272) | step 3770 | avg_nll=13.86 avg_ppl=6.54 speed=2260.62 words/sec time_elapsed=276.91 sec\n",
            "14\n",
            "12\n",
            "15\n",
            "13\n",
            "13\n",
            "12\n",
            "14\n",
            "13\n",
            "15\n",
            "13\n",
            "epoch 14 (243/272) | step 3780 | avg_nll=13.12 avg_ppl=6.14 speed=1410.23 words/sec time_elapsed=278.55 sec\n",
            "15\n",
            "14\n",
            "15\n",
            "14\n",
            "15\n",
            "14\n",
            "13\n",
            "14\n",
            "14\n",
            "14\n",
            "epoch 14 (253/272) | step 3790 | avg_nll=13.14 avg_ppl=6.42 speed=2333.24 words/sec time_elapsed=279.52 sec\n",
            "12\n",
            "13\n",
            "15\n",
            "13\n",
            "12\n",
            "12\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "epoch 14 (263/272) | step 3800 | avg_nll=12.97 avg_ppl=5.99 speed=2487.58 words/sec time_elapsed=280.46 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 3800 | dev_ppl=9.35693073272705\n",
            "epoch 14 step 3800: save currently the best model to 'model.pt'\n",
            "13\n",
            "11\n",
            "14\n",
            "13\n",
            "13\n",
            "14\n",
            "17\n",
            "12\n",
            "13\n",
            "14\n",
            "epoch 15 (1/272) | step 3810 | avg_nll=12.55 avg_ppl=5.86 speed=1524.33 words/sec time_elapsed=281.95 sec\n",
            "15\n",
            "14\n",
            "13\n",
            "11\n",
            "15\n",
            "12\n",
            "12\n",
            "12\n",
            "15\n",
            "12\n",
            "epoch 15 (11/272) | step 3820 | avg_nll=12.20 avg_ppl=5.43 speed=2515.93 words/sec time_elapsed=282.87 sec\n",
            "18\n",
            "12\n",
            "14\n",
            "14\n",
            "12\n",
            "14\n",
            "14\n",
            "13\n",
            "15\n",
            "15\n",
            "epoch 15 (21/272) | step 3830 | avg_nll=12.93 avg_ppl=5.83 speed=2460.15 words/sec time_elapsed=283.82 sec\n",
            "13\n",
            "15\n",
            "14\n",
            "12\n",
            "13\n",
            "16\n",
            "15\n",
            "14\n",
            "12\n",
            "15\n",
            "epoch 15 (31/272) | step 3840 | avg_nll=12.47 avg_ppl=5.59 speed=2140.34 words/sec time_elapsed=284.90 sec\n",
            "15\n",
            "12\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "14\n",
            "14\n",
            "12\n",
            "14\n",
            "epoch 15 (41/272) | step 3850 | avg_nll=12.13 avg_ppl=5.53 speed=1199.50 words/sec time_elapsed=286.80 sec\n",
            "13\n",
            "13\n",
            "12\n",
            "15\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "15\n",
            "15\n",
            "epoch 15 (51/272) | step 3860 | avg_nll=13.70 avg_ppl=6.45 speed=995.33 words/sec time_elapsed=289.16 sec\n",
            "12\n",
            "15\n",
            "14\n",
            "12\n",
            "17\n",
            "14\n",
            "11\n",
            "15\n",
            "14\n",
            "15\n",
            "epoch 15 (61/272) | step 3870 | avg_nll=11.90 avg_ppl=5.34 speed=1684.99 words/sec time_elapsed=290.51 sec\n",
            "13\n",
            "15\n",
            "14\n",
            "12\n",
            "13\n",
            "15\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "epoch 15 (71/272) | step 3880 | avg_nll=12.84 avg_ppl=5.92 speed=2746.91 words/sec time_elapsed=291.35 sec\n",
            "14\n",
            "16\n",
            "13\n",
            "11\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "13\n",
            "16\n",
            "epoch 15 (81/272) | step 3890 | avg_nll=12.22 avg_ppl=5.50 speed=1960.47 words/sec time_elapsed=292.52 sec\n",
            "14\n",
            "11\n",
            "14\n",
            "13\n",
            "16\n",
            "12\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "epoch 15 (91/272) | step 3900 | avg_nll=13.38 avg_ppl=6.24 speed=2561.41 words/sec time_elapsed=293.43 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 3900 | dev_ppl=9.638554573059082\n",
            "14\n",
            "14\n",
            "14\n",
            "13\n",
            "15\n",
            "13\n",
            "14\n",
            "12\n",
            "13\n",
            "15\n",
            "epoch 15 (101/272) | step 3910 | avg_nll=12.69 avg_ppl=5.74 speed=1667.11 words/sec time_elapsed=294.83 sec\n",
            "13\n",
            "15\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "14\n",
            "11\n",
            "14\n",
            "17\n",
            "epoch 15 (111/272) | step 3920 | avg_nll=13.58 avg_ppl=6.46 speed=2537.42 words/sec time_elapsed=295.75 sec\n",
            "15\n",
            "15\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "16\n",
            "17\n",
            "14\n",
            "epoch 15 (121/272) | step 3930 | avg_nll=14.49 avg_ppl=7.24 speed=2496.74 words/sec time_elapsed=296.69 sec\n",
            "12\n",
            "15\n",
            "14\n",
            "14\n",
            "12\n",
            "14\n",
            "13\n",
            "12\n",
            "14\n",
            "13\n",
            "epoch 15 (131/272) | step 3940 | avg_nll=12.99 avg_ppl=5.86 speed=2646.17 words/sec time_elapsed=297.58 sec\n",
            "15\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "14\n",
            "13\n",
            "15\n",
            "15\n",
            "14\n",
            "epoch 15 (141/272) | step 3950 | avg_nll=13.11 avg_ppl=6.11 speed=2475.32 words/sec time_elapsed=298.51 sec\n",
            "13\n",
            "12\n",
            "15\n",
            "13\n",
            "13\n",
            "13\n",
            "12\n",
            "14\n",
            "14\n",
            "14\n",
            "epoch 15 (151/272) | step 3960 | avg_nll=13.20 avg_ppl=6.31 speed=2040.80 words/sec time_elapsed=299.64 sec\n",
            "13\n",
            "15\n",
            "13\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "epoch 15 (161/272) | step 3970 | avg_nll=11.89 avg_ppl=5.43 speed=1077.25 words/sec time_elapsed=301.73 sec\n",
            "12\n",
            "16\n",
            "14\n",
            "13\n",
            "15\n",
            "14\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "epoch 15 (171/272) | step 3980 | avg_nll=13.08 avg_ppl=5.98 speed=1005.19 words/sec time_elapsed=304.06 sec\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "17\n",
            "15\n",
            "13\n",
            "14\n",
            "15\n",
            "12\n",
            "epoch 15 (181/272) | step 3990 | avg_nll=13.08 avg_ppl=6.05 speed=1479.61 words/sec time_elapsed=305.63 sec\n",
            "13\n",
            "14\n",
            "12\n",
            "13\n",
            "12\n",
            "15\n",
            "15\n",
            "13\n",
            "14\n",
            "12\n",
            "epoch 15 (191/272) | step 4000 | avg_nll=11.57 avg_ppl=5.16 speed=1462.86 words/sec time_elapsed=307.18 sec\n",
            "Begin validation ...\n",
            "16\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "11\n",
            "12\n",
            "12\n",
            "13\n",
            "11\n",
            "13\n",
            "14\n",
            "12\n",
            "12\n",
            "12\n",
            "9\n",
            "validation: step 4000 | dev_ppl=9.61241340637207\n",
            "13\n",
            "14\n",
            "13\n",
            "12\n",
            "13\n",
            "12\n",
            "13\n",
            "15\n",
            "14\n",
            "13\n",
            "epoch 15 (201/272) | step 4010 | avg_nll=13.75 avg_ppl=6.54 speed=2594.91 words/sec time_elapsed=308.08 sec\n",
            "15\n",
            "13\n",
            "15\n",
            "13\n",
            "16\n",
            "13\n",
            "14\n",
            "12\n",
            "14\n",
            "12\n",
            "epoch 15 (211/272) | step 4020 | avg_nll=13.48 avg_ppl=6.30 speed=4305.60 words/sec time_elapsed=308.62 sec\n",
            "13\n",
            "17\n",
            "14\n",
            "12\n",
            "13\n",
            "12\n",
            "14\n",
            "15\n",
            "14\n",
            "13\n",
            "epoch 15 (221/272) | step 4030 | avg_nll=13.37 avg_ppl=6.18 speed=4035.19 words/sec time_elapsed=309.21 sec\n",
            "11\n",
            "16\n",
            "16\n",
            "13\n",
            "12\n",
            "14\n",
            "12\n",
            "12\n",
            "16\n",
            "14\n",
            "epoch 15 (231/272) | step 4040 | avg_nll=13.71 avg_ppl=6.61 speed=3917.76 words/sec time_elapsed=309.80 sec\n",
            "12\n",
            "14\n",
            "12\n",
            "14\n",
            "12\n",
            "13\n",
            "13\n",
            "14\n",
            "13\n",
            "13\n",
            "epoch 15 (241/272) | step 4050 | avg_nll=13.03 avg_ppl=6.11 speed=4084.88 words/sec time_elapsed=310.36 sec\n",
            "13\n",
            "14\n",
            "14\n",
            "15\n",
            "17\n",
            "13\n",
            "15\n",
            "13\n",
            "14\n",
            "15\n",
            "epoch 15 (251/272) | step 4060 | avg_nll=13.73 avg_ppl=6.58 speed=3916.07 words/sec time_elapsed=310.96 sec\n",
            "12\n",
            "12\n",
            "12\n",
            "13\n",
            "14\n",
            "14\n",
            "13\n",
            "14\n",
            "13\n",
            "15\n",
            "epoch 15 (261/272) | step 4070 | avg_nll=12.69 avg_ppl=5.79 speed=3776.93 words/sec time_elapsed=311.57 sec\n",
            "14\n",
            "11\n",
            "12\n",
            "15\n",
            "13\n",
            "17\n",
            "15\n",
            "16\n",
            "14\n",
            "13\n",
            "epoch 15 (271/272) | step 4080 | avg_nll=13.10 avg_ppl=6.13 speed=4029.90 words/sec time_elapsed=312.15 sec\n",
            "Reached maximum number of epochs\n",
            "Number of batches in the training loader: 272\n",
            "17\n",
            "First batch: {'encoder_input_ids': tensor([[   1,   42,   75,   60, 2540,  564,   36,    2,    3,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   47,   60,  564,  110,  255,  865,   36,    2,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   66,  856,  274,  184, 1650,   36,    2,    3,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   66,   83,  193, 1140,   36,    2,    3,    3,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   42,   75,   60,  564,   36,    2,    3,    3,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   66,   83,  141,  318,  110,  176,   36,    2,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   47,   60, 1293,   64,  131,  365, 1453,   36,    2,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   79,   99,   68,   75,  200,   64, 1091,   36,    2,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   81,   57, 1018,   49,   65,  119,   68,   35,    7,    2,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   47,   60,  276,   64,  124,  959, 1920,   93,   36,    2,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   47,   60,  113,  141,  392,  482,   36,    2,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   47,  167,  131, 2212,  133,  113,  688,   36,    2,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   47,   49,   75,  103,   68,  726,   36,    2,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   47,   60,  332,  164,   47,   66,  103, 1817,   36,    2,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   90,   65,  141,  593,  110,  176,   36,    2,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   81,   57,   82, 1438,  239,   36,    2,    3,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   66,   83,  105,   64,  369,  112,   85,   58,  108,  119, 1747,\n",
            "          837,   49,   35,    5,    2],\n",
            "        [   1,   47,   60,  276,  110,  213,  131, 1221,  284,   36,    2,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   67,   65,  853,   36,    2,    3,    3,    3,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   67,   65,  661,   46, 2693,   58,  584, 2780,   36,    2,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   47,   60,  216,  660,   36,    2,    3,    3,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   47,  117,  403,  110,   81,   75,  183,   22,  530,  730,  435,\n",
            "           36,    2,    3,    3,    3],\n",
            "        [   1,  139,  125,  179,  450,  438,   36,    2,    3,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   79,   99,  218, 3054,   48,   46,  817,   36,    2,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   47,   60,  611,   36,    2,    3,    3,    3,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   81,   49,   57,   68,  555,  490,   36,    2,    3,    3,    3,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   67,  186, 2475,  216,   64,  105, 2214,  111,  546,   36,    2,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   67,   65,  986,   46,  109,  394, 1695,   64,  481,   36,    2,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   47,   60,  210,  138, 2362, 2776,  324, 2015,   35,  516,   36,\n",
            "            2,    3,    3,    3,    3],\n",
            "        [   1,   47,   60,  115,   75,  812,  999,  615,   64,  471,   36,    2,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   67,   65, 2905, 1445,  127,   64,  156,  113,  788,   36,    2,\n",
            "            3,    3,    3,    3,    3],\n",
            "        [   1,   47,   60,  117,  101,  168,   52,  140,   36,    2,    3,    3,\n",
            "            3,    3,    3,    3,    3]]), 'encoder_padding_mask': tensor([[False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True,  True,  True,  True,  True,  True]]), 'decoder_input_ids': tensor([[   1,   37,   42,  680,  215,   83,  141,   35,    2,    3,    3,    3],\n",
            "        [   1,   37,   42,  215,  190,   63, 1159,   35,    2,    3,    3,    3],\n",
            "        [   1,   47,   45,  102,   54,  101, 1007,   35,    2,    3,    3,    3],\n",
            "        [   1,   47,   45,   86,  144,   35,    2,    3,    3,    3,    3,    3],\n",
            "        [   1,   37,   42,  215,   35,    2,    3,    3,    3,    3,    3,    3],\n",
            "        [   1,   47,   78,  511,  185,  127,   35,    2,    3,    3,    3,    3],\n",
            "        [   1,   37,   42,  255,  451,   54,  698,   47, 1888,   35,    2,    3],\n",
            "        [   1,   64,   45,   60,  255,   35,    2,    3,    3,    3,    3,    3],\n",
            "        [   1,   47,   45, 1067,  208,   40,   47,   34,    7,    2,    3,    3],\n",
            "        [   1,   37,   42,  665,  135,  116,  363, 2344,  246, 2892,   35,    2],\n",
            "        [   1,   37,   42,   56, 1866,  334,   35,    2,    3,    3,    3,    3],\n",
            "        [   1,   37,   42,  102,   54, 2103,   47,   39, 2150,   76,   35,    2],\n",
            "        [   1,   37,   42,   60,  642,   35,    2,    3,    3,    3,    3,    3],\n",
            "        [   1,   37,   42,  160,  428,   37,  887,   47,   35,    2,    3,    3],\n",
            "        [   1,   71,   44,  600,  185,  127,   35,    2,    3,    3,    3,    3],\n",
            "        [   1,   47,   78,   39,  144,  385,   35,    2,    3,    3,    3,    3],\n",
            "        [   1,   47,   78,   86,  471,  168, 1541,   35,    2,    3,    3,    3],\n",
            "        [   1,   37,   42,  173,  141, 1173,   47,  179,   35,    2,    3,    3],\n",
            "        [   1,   51,   63,  501,  371,   35,    2,    3,    3,    3,    3,    3],\n",
            "        [   1,   51,   63,   39,  317,  120, 2356,   29,  224,   35,    2,    3],\n",
            "        [   1,   37,   42,  244,  179,   35,    2,    3,    3,    3,    3,    3],\n",
            "        [   1,   37,   42,  173,   47, 3141,  141,   35,    2,    3,    3,    3],\n",
            "        [   1,   90,   78,   56,  460,  672,   35,    2,    3,    3,    3,    3],\n",
            "        [   1,   64,   78,  719, 2423, 1956,   26,   35,    2,    3,    3,    3],\n",
            "        [   1,   37,   87,  558,   35,    2,    3,    3,    3,    3,    3,    3],\n",
            "        [   1,   47,   78,   60,  426,  192,   35,    2,    3,    3,    3,    3],\n",
            "        [   1,   51,   44,  244, 1082,  200,   56, 1397,   35,    2,    3,    3],\n",
            "        [   1,   51,   63, 2256,   54, 1258,   26,   83,  103,  294,   35,    2],\n",
            "        [   1,   37,   42,  139,   54, 2237,   35,    2,    3,    3,    3,    3],\n",
            "        [   1,   37,   42,   86,  603,   89, 3042,   83,  168,   35,    2,    3],\n",
            "        [   1,   51,   63, 1666,  135, 1212,   35,    2,    3,    3,    3,    3],\n",
            "        [   1,   37,   42, 1661,   35,    2,    3,    3,    3,    3,    3,    3]]), 'decoder_padding_mask': tensor([[False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False,  True,  True,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False,  True,  True,  True,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True],\n",
            "        [False, False, False, False, False, False, False,  True,  True,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False],\n",
            "        [False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False],\n",
            "        [False, False, False, False, False, False, False,  True,  True,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False,  True,  True,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True],\n",
            "        [False, False, False, False, False, False, False,  True,  True,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False,  True,  True,  True,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False],\n",
            "        [False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True],\n",
            "        [False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True],\n",
            "        [False, False, False, False, False, False,  True,  True,  True,  True,\n",
            "          True,  True]])}\n"
          ]
        }
      ],
      "source": [
        "# Set a random seed, so you obtain the same output model if you run this cell again.\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "model = EncoderDecoderModel(\n",
        "    source_vocab_size=source_tokenizer.vocab_size,\n",
        "    target_vocab_size=target_tokenizer.vocab_size,\n",
        "    hidden_size=32,\n",
        "    intermediate_size=32 * 4,\n",
        "    num_attention_heads=4,\n",
        "    num_encoder_layers=3,\n",
        "    num_decoder_layers=3,\n",
        "    max_sequence_length=32,\n",
        "    hidden_dropout_prob=0.1,\n",
        "    )\n",
        "\n",
        "print(\"Model architecture:\", model)\n",
        "print(\"Total number of trainable model parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "train(model, tokenized_datasets[\"train\"], tokenized_datasets[\"validation\"],\n",
        "      max_epoch=15, model_path=\"model.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhk9wiHzpyuF"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "We have trained a seq2seq model for the NMT task. Now let's evaluate the model on the test set by generating translations with beam search and comparing them to the gold translations using the BLEU score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqEeZlyeuzG2"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "def beam_search(model: EncoderDecoderModel,\n",
        "                encoder_input_ids: torch.LongTensor,\n",
        "                beam_width: int = 5,\n",
        "                max_len: int = 32) -> Tuple[torch.LongTensor, float]:\n",
        "    \"\"\"Run beam search on the encoder-decoder model for a single source sequence.\n",
        "\n",
        "    Args:\n",
        "        model: The encoder-decoder model.\n",
        "        encoder_input_ids: The input sequence. Tensor of shape [encoder_sequence_length].\n",
        "        beam_width: Number of generations to expand at each time step.\n",
        "        max_len: Stop generation when reaching this length for the generated sequence.\n",
        "\n",
        "    Returns:\n",
        "        A tuple (generation, score) where generation is the generated target sequence and\n",
        "            a tensor of shape [target_sequence_length] and score is the corresponding\n",
        "            log-probability of this generation.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    encoder_input_ids = encoder_input_ids.unsqueeze(0) # Add the batch dimension\n",
        "    encoder_padding_mask = torch.zeros_like(encoder_input_ids, dtype=torch.bool) # No padding\n",
        "    encoder_outputs = model.forward_encoder(encoder_input_ids, encoder_padding_mask)\n",
        "\n",
        "    generations = [torch.tensor([target_tokenizer.bos_token_id], device=encoder_input_ids.device)]\n",
        "    scores = [0.0]\n",
        "\n",
        "    best_generation = None\n",
        "    best_score = float('-inf')\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        new_generations = []\n",
        "        new_scores = []\n",
        "        for score, generation in zip(scores, generations):\n",
        "            generation = generation.unsqueeze(0) # Add the batch dimension\n",
        "            padding_mask = torch.zeros_like(generation, dtype=torch.bool) # No padding\n",
        "            decoder_output = model.forward_decoder(generation, padding_mask, encoder_outputs, encoder_padding_mask)\n",
        "            last_log_probs = decoder_output[0, -1, :].log_softmax(dim=-1)\n",
        "            top_log_probs, top_indices = last_log_probs.topk(beam_width, dim=-1)\n",
        "\n",
        "            new_generations.append(torch.cat([generation.expand(beam_width, -1), top_indices[:,None]], dim=1))\n",
        "            new_scores.append(score + top_log_probs)\n",
        "\n",
        "        new_generations = torch.cat(new_generations, dim=0)\n",
        "        new_scores = torch.cat(new_scores, dim=0)\n",
        "\n",
        "        ends_with_eos = target_tokenizer.eos_token_id == new_generations[:,-1]\n",
        "\n",
        "        if ends_with_eos.any():\n",
        "            new_completed_generations = new_generations[ends_with_eos]\n",
        "            new_completed_scores = new_scores[ends_with_eos]\n",
        "\n",
        "            if new_completed_scores.max() > best_score:\n",
        "                best_score = new_completed_scores.max()\n",
        "                best_generation = new_completed_generations[new_completed_scores.argmax()]\n",
        "\n",
        "        if best_score >= new_scores.max():\n",
        "            break\n",
        "\n",
        "        scores, indices = torch.topk(new_scores, beam_width, dim=-1)\n",
        "        generations = new_generations[indices]\n",
        "\n",
        "    if best_generation is None:\n",
        "        best_generation = generations[0]\n",
        "        best_score = scores[0]\n",
        "\n",
        "    return best_generation, best_score.cpu().item()\n",
        "\n",
        "\n",
        "def run_generation(model, test_dataset, beam_size=5, max_decoding_time_step=32):\n",
        "    \"\"\"Run beam search decoding on the test set, compute BLEU and return reference and candidate target sentences.\n",
        "    \"\"\"\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('Use device: %s' % device)\n",
        "\n",
        "    input_sentences = []\n",
        "    reference_sentences = []\n",
        "    candidate_sentences = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for example in tqdm(test_dataset):\n",
        "            encoder_input_ids = torch.tensor(example[\"encoder_input_ids\"], device=device)\n",
        "\n",
        "            generation, _ = beam_search(model, encoder_input_ids, beam_size, max_decoding_time_step)\n",
        "\n",
        "            # Decode given source sequence and generated target sequence and avoid special tokens\n",
        "\n",
        "            input_text = \"\".join(source_tokenizer.decode(token).replace(\"▁\", \" \") for token in example[\"encoder_input_ids\"][1:-1])\n",
        "            reference_text = \"\".join(target_tokenizer.decode(token).replace(\"▁\", \" \") for token in example[\"decoder_input_ids\"][1:-1])\n",
        "            candidate_text = \"\".join(target_tokenizer.decode(token).replace(\"▁\", \" \") for token in generation[1:-1].cpu())\n",
        "\n",
        "            reference_sentences.append(reference_text)\n",
        "            candidate_sentences.append(candidate_text)\n",
        "            input_sentences.append(input_text)\n",
        "\n",
        "\n",
        "    bleu_score = corpus_bleu([[ref] for ref in reference_sentences],\n",
        "                             [candidate for candidate in candidate_sentences])\n",
        "\n",
        "    return bleu_score, input_sentences, reference_sentences, candidate_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRjz11ntwgkK",
        "outputId": "3209d92b-5ce7-48d3-9509-9ddf17eeac56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 486/486 [00:42<00:00, 11.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Corpus BLEU: 47.10365261339995\n"
          ]
        }
      ],
      "source": [
        "# Restore the best validation checkpoint\n",
        "model.load_state_dict(torch.load(\"model.pt\"))\n",
        "\n",
        "bleu_score, inputs, references, candidates = run_generation(model, tokenized_datasets[\"test\"])\n",
        "print('\\n\\nCorpus BLEU: {}'.format(bleu_score * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOLmb9eh6kua"
      },
      "source": [
        "Let's look at some examples. What do you think of the quality of the translations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5e1cDYe6t0B",
        "outputId": "9916cb33-733d-410d-8ac3-c39aff2b50ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Sample 10 =====\n",
            "Input:  vous me mettez mal a l aise .\n",
            "Gold:  you re embarrassing me .\n",
            "Pred:  you re pretty to money .\n",
            "===== Sample 11 =====\n",
            "Input:  c est toi le professeur .\n",
            "Gold:  you re the teacher .\n",
            "Pred:  you re the teacher .\n",
            "===== Sample 12 =====\n",
            "Input:  elle sourit avec bonheur .\n",
            "Gold:  she smiled happily .\n",
            "Pred:  she is good at of that .\n",
            "===== Sample 13 =====\n",
            "Input:  je ne suis pas devin .\n",
            "Gold:  i m not a psychic .\n",
            "Pred:  i m not that old .\n",
            "===== Sample 14 =====\n",
            "Input:  vous allez perdre .\n",
            "Gold:  you re going to lose .\n",
            "Pred:  you re going to wise .\n",
            "===== Sample 15 =====\n",
            "Input:  vous me touchez .\n",
            "Gold:  you re touching me .\n",
            "Pred:  you re tired .\n",
            "===== Sample 16 =====\n",
            "Input:  je pars aujourd hui .\n",
            "Gold:  i m leaving today .\n",
            "Pred:  i m rich .\n",
            "===== Sample 17 =====\n",
            "Input:  je ne suis pas une sainte .\n",
            "Gold:  i m no saint .\n",
            "Pred:  i m not a teacher .\n",
            "===== Sample 18 =====\n",
            "Input:  je suis puissant .\n",
            "Gold:  i m powerful .\n",
            "Pred:  i m young .\n",
            "===== Sample 19 =====\n",
            "Input:  vous n etes qu un lache .\n",
            "Gold:  you re nothing but a coward .\n",
            "Pred:  you re not a coward .\n"
          ]
        }
      ],
      "source": [
        "# Feel free to change the range to look at more samples!\n",
        "for k in range(10, 20):\n",
        "  print(f\"===== Sample {k} =====\")\n",
        "  print(f\"Input: {inputs[k]}\")\n",
        "  print(f\"Gold: {references[k]}\")\n",
        "  print(f\"Pred: {candidates[k]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v648UANH1iIO"
      },
      "source": [
        "# Questions\n",
        "\n",
        "Please answer written questions from the assignment in this section. You can alter the provided code to obtain the answers, but be careful not to break anything!\n",
        "\n",
        "**(b) (4 points)**\n",
        "\n",
        "- (i)\n",
        "    What vocabulary size are we using for the source and target language?\n",
        "\n",
        "- (ii)\n",
        "    Approximately how many source and target tokens are on average contained in a training batch? What proportion of these tokens are `<pad>` tokens on average?\n",
        "\n",
        "- (iii)\n",
        "What is the specific purpose of saving the model parameters in a file `model.pt` throughout training in the code we provide?\n",
        "\n",
        "**(c) (2 points)**\n",
        "Manually look at some results and compare them with the gold answers. What do you think of the quality of the translations? Are these grammatical English sentences? Can you identify any common mistakes?\n",
        "\n",
        "**(d) (4 points)**\n",
        "Consider the provided beam search method. This implementation is not efficient and performs a lot of repeated computation. Identify the issue and propose how you can fix it.\n",
        "In particular, describe how would you have to change the arguments and return values of your EncoderDecoderModel and its sub-modules?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "2LvPHiteAvaN",
        "outputId": "b7b32b02-fe6a-4ce3-e541-9fc38d44fa5a"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unmatched ')' (<ipython-input-21-0b29d514ca02>, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-0b29d514ca02>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    a)\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
          ]
        }
      ],
      "source": [
        "(b)\n",
        "\n",
        "i)\n",
        "Vocab size of source language: 3200\n",
        "Vocab size of target language: 3200\n",
        "\n",
        "\n",
        "iii)\n",
        "Checkpointing for Recovery During training, the model parameters and optimizer state are periodically saved to allow recovery in case of interruptions.\n",
        "This is critical for long training processes that may be subject to interruptions due to hardware issues, power outages, or other unforeseen events.\n",
        "By saving checkpoints, training can be resumed from the last saved state without losing significant progress.\n",
        "\n",
        "(c)\n",
        "\n",
        " not good ,no, confuses adjectives with verbs the model doesnot know the difference between the adjectives and verbs.\n",
        "\n",
        " (d)\n",
        " The problem lies in the attention layer of the final decoder. Since the next generate token only depends on the final hidden state vector's \n",
        "value after the attention layer, \n",
        "we only need to compute the last row of the attention matrix for the last decoder in the decoder block.\n",
        "\n",
        "To fix this we can do the following:\n",
        "\n",
        "1- Add a new boolean parameter to TransformerBlock() called \"last_decoder\"\n",
        "\n",
        "2- Add a new boolean parameter to the forward function of TransformerBlock() called \"inference\"\n",
        "\n",
        "3- Add a new boolean parameter to the forward function of EncoderDecoderModel() called \"inference\"\n",
        "\n",
        "4- Add a new boolean parameter to the forward_decoder function of EncoderDecoderModel() called \"inference\"\n",
        "\n",
        "5- Add a new boolean parameter to MultiHeadAttention() called \"last_hidden_only\". If true, \n",
        "    the attention module will only calculate the attention scores for the last hidden state with the other hidden states.\n",
        "\n",
        "\n",
        "\n",
        "When generating at inference time, set the inference boolean to true in the EncoderDecoderModel's forward function. \n",
        "The EncoderDecoder model then eventually passes this boolean to the Decoders and only the last decoder is allowed to use the multiheaded attention module with \n",
        "the last_hidden_only parameter set to true when we are generating at inference time. \n",
        "We can also have the EncoderDecoder only return the logits resulting from the last hidden state instead of the logits for all hidden states."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odQ4BMC3go3i"
      },
      "source": [
        "### Function for counting pad/token ratio for question b, ii)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_BnECw-go3i",
        "outputId": "52880d6f-b1ac-4c79-bdee-04276a7564b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total for all batches:\n",
            " Tokens: 219794, Non-Pads: 149903, Pads: 69891\n",
            "Num Batches: 272\n",
            "Avg per batch:\n",
            " Tokens: 808.0661764705883, Non-Pads: 551.1139526367188, Pads: 256.95220947265625\n"
          ]
        }
      ],
      "source": [
        "def count_tokens_pad(training_dataset, batch_size=32):\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "    num_batches = len(train_loader)\n",
        "    total_batch_tokens = 0\n",
        "    total_batch_pads = 0\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "      total_batch_tokens += batch['encoder_input_ids'].numel() + batch['decoder_input_ids'].numel()\n",
        "      total_batch_pads += (batch['encoder_padding_mask']*1).sum() + (batch['decoder_padding_mask']*1).sum()\n",
        "\n",
        "\n",
        "\n",
        "    total_batch_nonpads= total_batch_tokens - total_batch_pads\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"Total for all batches:\\n Tokens: {total_batch_tokens}, Non-Pads: {total_batch_nonpads}, Pads: {total_batch_pads}\")\n",
        "    print(f\"Num Batches: {num_batches}\")\n",
        "    print(f\"Avg per batch:\\n Tokens: {total_batch_tokens/num_batches}, Non-Pads: {total_batch_nonpads/num_batches}, Pads: {total_batch_pads/num_batches}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "count_tokens_pad(tokenized_datasets[\"train\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08fd3a4beaa744e78e7029e9766cb31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "294394dd26ed40178c55f5c647cec9d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5613ad4441e84683aa07646e8448af12",
            "placeholder": "​",
            "style": "IPY_MODEL_f7cddb1dee2b432eb668b986edca502a",
            "value": " 8636/8701 [00:04&lt;00:00, 2089.26 examples/s]"
          }
        },
        "3444fc472222441d88f36a21bc2daf9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cad858bf52d41b288792ff4e12d9b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "536a65edd1c04a33bedcb308777aced6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d959144845e749fcbe7deef7065c72dc",
            "placeholder": "​",
            "style": "IPY_MODEL_a592f3a7e7a3461fa31a3fc0293e3c7a",
            "value": "Map:  93%"
          }
        },
        "5613ad4441e84683aa07646e8448af12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b7c898d0ae47108131e5c455bf2398": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b0888fad5504f5dbc88ff51e40696af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e59bc2e9566407fab71956ad510f2c7",
            "max": 8701,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b287d3e19e5f457cbd6bec68822c0590",
            "value": 8701
          }
        },
        "6bbe078bec8a486fb902a6eab83cc78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6eed8490a89e45e29d8de693f8a72cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d908d752459847bab9fe66e889e000f0",
            "placeholder": "​",
            "style": "IPY_MODEL_3444fc472222441d88f36a21bc2daf9f",
            "value": " 449/485 [00:00&lt;00:00, 1943.76 examples/s]"
          }
        },
        "72ad1817692c40c78060c6c570e77eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f17bcd37b54f4b10aecbf0b7c627a77c",
              "IPY_MODEL_835062f8dc29431496d714cd09001f85",
              "IPY_MODEL_b2f8f503f2e345d7b1682bcf42f0c9f2"
            ],
            "layout": "IPY_MODEL_e357a55ddf4f492caba77dec0b1d2946"
          }
        },
        "79f74e81239440da8834d636a518695a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_536a65edd1c04a33bedcb308777aced6",
              "IPY_MODEL_d10b305d26b24b198949e06d9d43ffc1",
              "IPY_MODEL_6eed8490a89e45e29d8de693f8a72cd1"
            ],
            "layout": "IPY_MODEL_9b6cf07e8351438fbbfe9302fa37a622"
          }
        },
        "7e59bc2e9566407fab71956ad510f2c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "831386bada174659a26f2eadb53ecc6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "835062f8dc29431496d714cd09001f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd2b8d43a32049e794e8bafc2cdbc3fd",
            "max": 486,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bbe078bec8a486fb902a6eab83cc78f",
            "value": 486
          }
        },
        "835d3d24c45042d5815eb29210eaf97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c966d56d63274cf48d7374eb883b1d67",
              "IPY_MODEL_6b0888fad5504f5dbc88ff51e40696af",
              "IPY_MODEL_294394dd26ed40178c55f5c647cec9d3"
            ],
            "layout": "IPY_MODEL_cd73d443cd5f4f1d9f0ca807bcb74a74"
          }
        },
        "9b6cf07e8351438fbbfe9302fa37a622": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a592f3a7e7a3461fa31a3fc0293e3c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab5ce00298824b2db2e5a05779ba8ba1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b287d3e19e5f457cbd6bec68822c0590": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2f8f503f2e345d7b1682bcf42f0c9f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64b7c898d0ae47108131e5c455bf2398",
            "placeholder": "​",
            "style": "IPY_MODEL_c4d6e58f4f274e4693039be4e5c66db8",
            "value": " 438/486 [00:00&lt;00:00, 1943.89 examples/s]"
          }
        },
        "bd2b8d43a32049e794e8bafc2cdbc3fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d6e58f4f274e4693039be4e5c66db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c966d56d63274cf48d7374eb883b1d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab5ce00298824b2db2e5a05779ba8ba1",
            "placeholder": "​",
            "style": "IPY_MODEL_831386bada174659a26f2eadb53ecc6d",
            "value": "Map:  99%"
          }
        },
        "cd73d443cd5f4f1d9f0ca807bcb74a74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "d10b305d26b24b198949e06d9d43ffc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec8045c5c9774e09a318bac5a50c57c3",
            "max": 485,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cad858bf52d41b288792ff4e12d9b99",
            "value": 485
          }
        },
        "d908d752459847bab9fe66e889e000f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d959144845e749fcbe7deef7065c72dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e357a55ddf4f492caba77dec0b1d2946": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "ec8045c5c9774e09a318bac5a50c57c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f17bcd37b54f4b10aecbf0b7c627a77c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff414e729b9a406bbe29aab8b8ca0b65",
            "placeholder": "​",
            "style": "IPY_MODEL_08fd3a4beaa744e78e7029e9766cb31f",
            "value": "Map:  90%"
          }
        },
        "f7cddb1dee2b432eb668b986edca502a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff414e729b9a406bbe29aab8b8ca0b65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
